{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This Notebook implements various standard CF methods using the PCP procedures as input and Spesialist procedures as output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# http://surprise.readthedocs.io/en/stable/getting_started.html\n",
    "# I believe in loading all the datasets from pandas df \n",
    "# you can also load dataset from csv and whatever suits\n",
    "\n",
    "\n",
    "# load the data in a form suitable for recommender system models: user, item, rating\n",
    "\n",
    "ratings = pd.read_csv('data_processing/CF_data_train.csv') # reading data in pandas df\n",
    "ratings_test = pd.read_csv('data_processing/CF_data_test.csv') # reading data in pandas df\n",
    "\n",
    "\n",
    "from surprise import Reader, Dataset\n",
    "\n",
    "\n",
    "# Train data:\n",
    "\n",
    "## to load dataset from pandas df, we need `load_fromm_df` method in surprise lib\n",
    "\n",
    "ratings_dict = {'itemID': list(ratings.Proc),\n",
    "                'userID': list(ratings.PC_enc),\n",
    "                'rating': list(ratings.rating)}\n",
    "\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is required.\n",
    "# The Reader class is used to parse a file containing ratings.\n",
    "reader = Reader(rating_scale=(0, 1.0))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n",
    "\n",
    "########################\n",
    "\n",
    "# Test data:\n",
    "\n",
    "## to load dataset from pandas df, we need `load_fromm_df` method in surprise lib\n",
    "\n",
    "ratings_test_dict = {'itemID': list(ratings_test.Proc),\n",
    "                'userID': list(ratings_test.PC_enc),\n",
    "                'rating': list(ratings_test.rating)}\n",
    "\n",
    "df_test = pd.DataFrame(ratings_test_dict)\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is required.\n",
    "# The Reader class is used to parse a file containing ratings.\n",
    "reader = Reader(rating_scale=(0, 1.0))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data_test = Dataset.load_from_df(df_test[['userID', 'itemID', 'rating']], reader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.co_clustering.CoClustering at 0x7f8252917198>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD\n",
    "from surprise.prediction_algorithms.co_clustering import CoClustering\n",
    "\n",
    "# sample random trainset and testset\n",
    "# test set is made of 25% of the ratings.\n",
    "#trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = CoClustering()\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "\n",
    "#build full trainset and use cross validation for evaluation\n",
    "trainset= data.build_full_trainset()\n",
    "\n",
    "#testset = data_test.build_full_trainset()\n",
    "\n",
    "algo.fit(trainset)\n",
    "\n",
    "\n",
    "\n",
    "# Than predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "#testset = testset.build_anti_testset()\n",
    "#predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PC_enc', 'F0_y_y', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8',\n",
      "       'F9', 'F10_y', 'F11_y', 'F12_y', 'F13_y', 'F14_y', 'F15_y', 'F16_y',\n",
      "       'F17_y', 'F18_y', 'F19_y', 'F20_y', 'F21_y', 'F22_y', 'F23_y', 'F24_y',\n",
      "       'F25_y', 'F26_y', 'F27_y', 'F28_y', 'F29_y', 'F30_y', 'F31_y', 'F32_y',\n",
      "       'F33_y', 'F34_y', 'F35_y', 'F36_y', 'F37_y', 'F38_y', 'F39_y', 'F40_y',\n",
      "       'F41_y', 'F42_y', 'F43_y', 'F44_y', 'F45_y', 'F46_y', 'F47_y', 'F48_y',\n",
      "       'F49_y', 'F50_y', 'F51_y', 'F52_y', 'F53_y', 'F54_y', 'F55_y', 'F56_y',\n",
      "       'F57_y', 'F58_y', 'F59_y', 'F60_y'],\n",
      "      dtype='object')\n",
      "660    131023122942\n",
      "883    131023156693\n",
      "885    131023214462\n",
      "887    131023214801\n",
      "888    131023242322\n",
      "Name: PC_enc, dtype: int64\n",
      "           PC_enc    F0_y_y        F1        F2   F3        F4        F5  \\\n",
      "660  131023122942  0.419003  0.285912  0.126592  0.0  0.165865  0.174652   \n",
      "883  131023156693  0.419003  0.285912  0.126592  0.0  0.165865  0.174652   \n",
      "885  131023214462  0.419003  0.285912  0.126592  0.0  0.165865  0.174652   \n",
      "887  131023214801  0.419003  0.285912  0.126592  0.0  0.165865  0.174652   \n",
      "888  131023242322  0.419003  0.285912  0.126592  0.0  0.165865  0.174652   \n",
      "\n",
      "           F6        F7   F8  ...  F51_y  F52_y  F53_y  F54_y  F55_y  F56_y  \\\n",
      "660  0.043501  0.100834  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "883  0.043501  0.100834  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "885  0.043501  0.100834  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "887  0.043501  0.100834  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "888  0.043501  0.100834  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "     F57_y  F58_y  F59_y  F60_y  \n",
      "660    0.0    0.0    0.0    0.0  \n",
      "883    0.0    0.0    0.0    0.0  \n",
      "885    0.0    0.0    0.0    0.0  \n",
      "887    0.0    0.0    0.0    0.0  \n",
      "888    0.0    0.0    0.0    0.0  \n",
      "\n",
      "[5 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "#tempset = data_test.build_full_trainset()\n",
    "#testset = tempset.build_testset()\n",
    "# first load the whole test data set\n",
    "data_test = pd.read_csv('data_processing/data_test.csv')\n",
    "#df_test = pd.read_csv('data/data_test.csv').sort_values('PC_enc')\n",
    "\n",
    "# Then only pick the PC_enc + specialist procedures from the test dataset for prediction\n",
    "my_test = data_test[[data_test.columns[0]]+ list(data_test.columns[407:])].sort_values('PC_enc')\n",
    "\n",
    "\n",
    "\n",
    "print(my_test.columns)\n",
    "print(my_test['PC_enc'].head())\n",
    "\n",
    "df_new = pd.DataFrame({'PC_enc':my_test['PC_enc']})\n",
    "#print(my_test.columns[0])\n",
    "#print(my_test.columns[1])\n",
    "\n",
    "for col in my_test.columns[1:]:\n",
    "    #print(col)\n",
    "    A = []\n",
    "    for enc in my_test['PC_enc']:\n",
    "        pred = algo.predict(uid=enc, iid=col, r_ui=0, verbose=False).est\n",
    "        #print(col, enc, pred)\n",
    "        A.append(pred)\n",
    "    \n",
    "    df_new[col] = A\n",
    "    \n",
    "print(df_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "df_new.to_csv('evaluation/data/CF_CClustering_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Draft\n",
    "\n",
    "def get_Iu(uid):\n",
    "    \"\"\" return the number of items rated by given user\n",
    "    args: \n",
    "      uid: the id of the user\n",
    "    returns: \n",
    "      the number of items rated by the user\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return len(trainset.ur[trainset.to_inner_uid(uid)])\n",
    "    except ValueError: # user was not part of the trainset\n",
    "        return 0\n",
    "    \n",
    "def get_Ui(iid):\n",
    "    \"\"\" return number of users that have rated given item\n",
    "    args:\n",
    "      iid: the raw id of the item\n",
    "    returns:\n",
    "      the number of users that have rated the item.\n",
    "    \"\"\"\n",
    "    try: \n",
    "        return len(trainset.ir[trainset.to_inner_iid(iid)])\n",
    "    except ValueError:\n",
    "        return 0\n",
    "    \n",
    "df = pd.DataFrame(predictions, columns=['uid', 'iid', 'rui', 'est', 'details'])\n",
    "df['Iu'] = df.uid.apply(get_Iu)\n",
    "df['Ui'] = df.iid.apply(get_Ui)\n",
    "#df['err'] = abs(df.est - df.rui)\n",
    "#best_predictions = df.sort_values(by='err')[:10]\n",
    "#worst_predictions = df.sort_values(by='err')[-10:]\n",
    "#print(worst_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             uid  iid  rui       est                    details   Iu     Ui\n",
      "0   131024494490  F60  0.0  0.000000  {'was_impossible': False}  122  21680\n",
      "1   131024494490   F6  0.0  0.156303  {'was_impossible': False}  122  21680\n",
      "2   131024494490  F59  0.0  0.000000  {'was_impossible': False}  122  21680\n",
      "3   131024494490  F58  0.0  0.000000  {'was_impossible': False}  122  21680\n",
      "4   131024494490  F57  0.0  0.010011  {'was_impossible': False}  122  21680\n",
      "5   131024494490  F56  0.0  0.000000  {'was_impossible': False}  122  21680\n",
      "6   131024494490  F55  0.0  0.000000  {'was_impossible': False}  122  21680\n",
      "7   131024494490  F54  0.0  0.000000  {'was_impossible': False}  122  21680\n",
      "8   131024494490  F53  0.0  0.000000  {'was_impossible': False}  122  21680\n",
      "9   131024494490  F16  0.0  0.025264  {'was_impossible': False}  122  21680\n",
      "10  131024494490  F51  0.0  0.011449  {'was_impossible': False}  122  21680\n",
      "11  131024494490  F44  0.0  0.000458  {'was_impossible': False}  122  21680\n",
      "12  131024494490   F4  0.0  0.310974  {'was_impossible': False}  122  21680\n",
      "13  131024494490  F40  0.0  0.012997  {'was_impossible': False}  122  21680\n",
      "14  131024494490  F41  0.0  0.005216  {'was_impossible': False}  122  21680\n",
      "15  131024494490  F42  0.0  0.007251  {'was_impossible': False}  122  21680\n",
      "16  131024494490  F43  0.0  0.015858  {'was_impossible': False}  122  21680\n",
      "17  131024494490  F50  0.0  0.058479  {'was_impossible': False}  122  21680\n",
      "18  131024494490  F45  0.0  0.016068  {'was_impossible': False}  122  21680\n",
      "19  131024494490  F47  0.0  0.008070  {'was_impossible': False}  122  21680\n",
      "20  131024494490  F48  0.0  0.000000  {'was_impossible': False}  122  21680\n",
      "21  131024494490  F49  0.0  0.000000  {'was_impossible': False}  122  21680\n",
      "22  131024494490   F5  0.0  0.114815  {'was_impossible': False}  122  21680\n",
      "23  131024494490  F46  0.0  0.001458  {'was_impossible': False}  122  21680\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df[df.uid==131024494490])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Y = np.load('data_processing/SP_pr_v2.npy')[:,31:]\n",
    "#X = np.load('data_processing/PC_pr.npy')\n",
    "\n",
    "\n",
    "#print(Z.shape)\n",
    "\n",
    "d = X.shape[1]\n",
    "N = X.shape[0]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "i= 34\n",
    "A = np.logical_or(X,Y).astype(int)\n",
    "print(X[i,0:30])\n",
    "print(Y[i,0:30])\n",
    "print(A[i,0:30])\n",
    "\n",
    "# shuffle the data\n",
    "I = np.random.permutation(N)\n",
    "\n",
    "A = A[I,:]\n",
    "\n",
    "\n",
    "# train and test\n",
    "N_train = 4500\n",
    "\n",
    "A_train = A[:N_train,:]\n",
    "A_test = A[N_train:,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: MF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Jackard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{43, 15, 53, 54, 29} {0, 32, 2, 4, 5, 37, 7, 10, 11, 14, 46, 16, 17, 18, 50, 23, 30}\n",
      "{34, 36, 39, 15, 31} {0, 1, 12}\n",
      "{0, 43, 15, 53, 26} {0, 1, 2, 39, 8, 15, 29}\n",
      "{43, 15, 53, 27, 31} {0, 1, 4}\n",
      "{34, 43, 13, 26, 27} {0, 1, 6, 39, 44, 13, 15, 50, 56, 29}\n",
      "{1, 43, 53, 26, 31} {0, 1, 2, 39, 8, 29}\n",
      "{13, 46, 54, 23, 26} {0, 6, 39, 13, 50, 56, 58, 29}\n",
      "{43, 15, 52, 21, 22} {0, 1, 4, 5, 10, 28, 30, 31}\n",
      "{43, 14, 50, 23, 26} {4, 43, 50, 21, 24, 30}\n",
      "{7, 43, 15, 53, 27} {0, 2, 6}\n",
      "{1, 14, 21, 23, 26} {0, 4, 39, 8, 10, 50, 56, 58, 29, 31}\n",
      "{43, 13, 15, 53, 27} {2, 4, 6, 10, 13}\n",
      "{1, 43, 13, 15, 53} {0, 1, 4, 36, 10, 17, 57, 28}\n",
      "{34, 43, 15, 53, 27} {0, 1, 2, 4, 6, 9, 20}\n",
      "{43, 13, 15, 53, 26} {0, 1, 39, 8, 15, 29}\n",
      "{1, 3, 40, 21, 26} {0, 50, 21}\n",
      "{43, 15, 53, 27, 31} {0, 1}\n",
      "{43, 15, 53, 26, 27} {0, 6, 39, 13, 29}\n",
      "{34, 43, 13, 53, 27} {2, 5, 6, 7, 9, 10, 11, 44, 13, 19, 21, 23}\n",
      "{15, 52, 21, 22, 26} {0, 1, 4, 10, 21, 28, 30}\n",
      "{0, 1, 36, 13, 26} {26}\n",
      "{15, 53, 22, 24, 26} {27, 34, 19, 21}\n",
      "{36, 5, 15, 52, 29} {4, 5, 10, 17, 28}\n",
      "{34, 21, 53, 22, 27} {0, 1, 4, 6, 7, 9, 10, 41, 43, 13, 46, 49, 19, 20, 21, 25, 27}\n",
      "{38, 15, 21, 23, 28} {6, 8, 10, 13, 14, 18, 50, 20, 60}\n",
      "{0, 43, 46, 52, 21} {5}\n",
      "{43, 15, 53, 27, 31} {0, 1}\n",
      "{1, 34, 53, 54, 59} {31, 23}\n",
      "{43, 15, 53, 27, 31} {0, 1}\n",
      "{43, 15, 52, 22, 29} {0, 1, 2, 34, 4, 5, 10, 17, 28, 30, 31}\n",
      "{43, 15, 53, 27, 31} {0, 1}\n",
      "{13, 46, 15, 52, 29} {2, 5, 10, 17, 54, 28}\n",
      "{1, 15, 53, 22, 26} {0, 2, 29, 39}\n",
      "{43, 15, 53, 54, 27} {0, 1, 7}\n",
      "{43, 15, 53, 27, 31} {0, 1}\n",
      "{34, 43, 15, 53, 26} {0, 1, 22, 15}\n",
      "{0, 5, 52, 22, 29} {17, 10, 28, 5}\n",
      "{43, 15, 18, 53, 27} {33, 4, 6, 7, 38, 9, 10, 11, 43, 13, 14, 16, 49, 18, 19, 20, 25, 30, 31}\n",
      "{34, 36, 39, 15, 31} {0, 1, 12}\n",
      "{34, 36, 39, 15, 31} {0, 1, 12}\n",
      "{1, 36, 15, 53, 29} {0, 17, 4}\n",
      "{34, 43, 13, 53, 27} {0, 1, 2, 4, 37, 6, 9, 10, 42, 13, 20}\n",
      "{32, 34, 9, 13, 15} {47, 31}\n",
      "{4, 20, 53, 54, 29} {0, 1, 8, 43, 50}\n",
      "{1, 14, 54, 23, 26} {0, 1, 4, 39, 50, 56, 58, 29, 31}\n",
      "{34, 13, 53, 27, 28} {5, 37, 8, 42, 11, 17}\n",
      "{2, 34, 53, 26, 27} {5, 11, 14, 18, 55, 23}\n",
      "{36, 39, 15, 26, 29} {0, 2, 39, 12, 13, 28, 29}\n",
      "{36, 43, 15, 53, 29} {0, 1, 2, 4, 17}\n",
      "{34, 38, 15, 53, 27} {9, 13, 6}\n",
      "{43, 50, 53, 26, 27} {0, 1, 39, 8, 11, 29}\n",
      "{43, 15, 53, 27, 31} {0, 1}\n",
      "{34, 50, 53, 22, 27} {0, 1, 2, 4, 5, 6, 9, 10, 13, 14, 17, 18, 19, 20, 21, 23, 25, 27, 28, 31, 41, 43, 46, 49, 50}\n",
      "{13, 14, 52, 21, 29} {2, 4, 5, 10, 28}\n",
      "{43, 15, 53, 54, 27} {0, 1, 7}\n",
      "{1, 36, 43, 50, 22} {2, 44}\n",
      "{34, 59, 15, 50, 27} {4, 17, 52, 21, 31}\n",
      "{0, 1, 36, 43, 15} set()\n",
      "{9, 15, 52, 53, 26} {0, 1, 34}\n",
      "{34, 18, 53, 22, 27} {34, 4, 6, 9, 13, 19, 21, 25}\n",
      "{43, 13, 15, 50, 53} {29, 13, 6, 39}\n",
      "{51, 53, 26, 60, 29} {48, 29, 39}\n",
      "{1, 43, 50, 53, 27} {0, 57, 11, 36}\n",
      "{11, 13, 53, 22, 26} {45, 2, 19, 21}\n",
      "{36, 22, 26, 29, 31} {0, 2, 4, 5}\n",
      "{34, 39, 43, 15, 22} {12}\n",
      "{0, 1, 36, 43, 15} set()\n",
      "{1, 43, 15, 50, 26} {0, 1, 2, 4, 6, 39, 9, 13, 50, 28, 29, 31}\n",
      "{43, 15, 53, 27, 31} {0, 1}\n",
      "{0, 36, 46, 28, 29} {17, 5}\n",
      "{34, 3, 4, 5, 13} {17, 4, 21}\n",
      "{0, 1, 53, 22, 26} {0, 8, 29, 39}\n",
      "{43, 15, 53, 25, 29} {0, 1, 2, 4, 10, 17, 24, 28}\n",
      "{1, 39, 54, 23, 26} {0, 39, 50, 56, 58, 29}\n",
      "{39, 43, 51, 52, 21} {32, 35, 5, 7, 10, 43, 14, 16, 18, 20, 53, 23}\n",
      "{0, 1, 36, 43, 15} set()\n",
      "{43, 18, 20, 54, 27} {52, 5}\n",
      "{0, 1, 43, 53, 26} {0, 1, 39, 8, 29}\n",
      "{34, 39, 43, 15, 22} {12}\n",
      "{34, 43, 15, 53, 22} {0, 1, 2, 4, 6, 9, 20, 22, 26}\n",
      "{39, 43, 15, 53, 26} {0, 1, 2, 7, 11, 14, 15, 16, 18, 55, 23, 30}\n",
      "{0, 43, 50, 53, 26} {8, 29, 39}\n",
      "{1, 7, 53, 26, 31} {0}\n",
      "{34, 43, 15, 53, 28} {0, 1, 2, 4, 6, 9, 20, 22, 31}\n",
      "{34, 9, 43, 53, 27} {0, 1, 2, 4, 5, 6, 9, 46, 50, 20, 52, 30, 31}\n",
      "{34, 43, 15, 53, 31} {0, 1, 4, 8, 12}\n",
      "{43, 13, 15, 50, 27} {2, 3, 4, 6, 13, 21, 28}\n",
      "{1, 34, 53, 21, 26} {0, 4, 21, 52}\n",
      "{34, 4, 43, 15, 53} {2, 11, 4, 23}\n",
      "{0, 43, 46, 52, 21} {5}\n",
      "{1, 7, 53, 26, 31} {0}\n",
      "{1, 34, 35, 38, 19} {40, 50}\n",
      "{1, 34, 3, 4, 27} {17, 4, 21, 52}\n",
      "{36, 15, 53, 29, 31} {0, 2, 4, 5, 17}\n",
      "{8, 43, 15, 52, 53} {0, 1, 2, 3, 7, 13, 14, 16, 30}\n",
      "{43, 13, 15, 53, 26} {0, 1, 4, 7, 8, 39, 15, 16, 29, 31}\n",
      "{43, 15, 53, 27, 31} {0, 1}\n",
      "{43, 50, 53, 26, 29} {2, 34, 4, 54, 24}\n",
      "{0, 5, 13, 17, 52} {17, 42}\n",
      "{43, 13, 53, 22, 26} {0, 1, 2, 5, 39, 8, 44, 15, 60, 29}\n",
      "0.09399999999999999\n"
     ]
    }
   ],
   "source": [
    "p=5\n",
    "J = np.zeros(100)\n",
    "for i in range(100):\n",
    "    A = set(np.argsort(-pred[i,:])[:p])\n",
    "    B = set(np.where(A_test[i,:]==1)[0])\n",
    "    J[i] = len(A.intersection(B))/p #/len(A.union(B))\n",
    "    print(A,B)\n",
    "\n",
    "print(np.mean(J))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### probability threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4736147716541023\n"
     ]
    }
   ],
   "source": [
    "#print( set(pred[i,np.where(pred[25,:]>0.2)[0]]))\n",
    "\n",
    "J = np.zeros(1000)\n",
    "for i in range(1000):\n",
    "    A = set(np.where(pred[i,:]>0.4)[0])\n",
    "    B = set(np.where(y_test[i,:]==1)[0])\n",
    "    J[i] = len(A.intersection(B))/len(A) #/len(A.union(B))\n",
    "\n",
    "print(np.mean(J))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the percentage of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56284658 0.43715342 0.21072089 0.00924214 0.24399261 0.1922366\n",
      " 0.1284658  0.12107209 0.12939002 0.07486137 0.16358595 0.05822551\n",
      " 0.08225508 0.08780037 0.06099815 0.10813309 0.04990758 0.09704251\n",
      " 0.04251386 0.03789279 0.04158965 0.07855823 0.025878   0.08595194\n",
      " 0.0194085  0.0323475  0.03327172 0.01571165 0.11460259 0.11460259\n",
      " 0.01848429 0.05360444 0.02495379 0.02310536 0.04343808 0.02310536\n",
      " 0.04066543 0.02402957 0.01756007 0.11460259 0.01571165 0.00554529\n",
      " 0.02680222 0.01478743 0.01478743 0.01201479 0.00831793 0.02033272\n",
      " 0.03142329 0.01201479 0.05360444 0.00369686 0.02402957 0.00739372\n",
      " 0.01756007 0.0064695  0.02218115 0.01848429 0.02125693 0.0064695\n",
      " 0.0064695 ]\n",
      "[0.7230316  0.500941   0.328649   0.1599551  0.28746173 0.3005466\n",
      " 0.31592745 0.24927387 0.13052641 0.1918064  0.22012499 0.21638663\n",
      " 0.25570133 0.312817   0.22577952 0.21150313 0.20382686 0.32516876\n",
      " 0.14882538 0.13547121 0.19084738 0.09776655 0.14411257 0.15672007\n",
      " 0.2337083  0.11784337 0.16430606 0.20043522 0.14219275 0.20694032\n",
      " 0.16580266 0.24449837 0.13126232 0.14978456 0.19708768 0.17116079\n",
      " 0.23430593 0.08652422 0.15307894 0.288802   0.16875088 0.11291631\n",
      " 0.23729761 0.10386355 0.20615318 0.10218002 0.15107764 0.12005347\n",
      " 0.18288787 0.19295675 0.12855306 0.14817081 0.17818306 0.20294194\n",
      " 0.14080904 0.2089086  0.16779597 0.25264472 0.11042209 0.04235668\n",
      " 0.24719463]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_test,axis=0))\n",
    "print(np.mean(pred,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011090573012939002\n",
      "0.1599551\n",
      "0.033828806\n"
     ]
    }
   ],
   "source": [
    "print(np.where(pred[:,3]>0.3)[0].shape[0]/pred.shape[0])\n",
    "print(np.mean(pred[:,3]))\n",
    "print(np.std(pred[:,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print some of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1} {0, 1, 2}\n",
      "{0, 1} {0, 1, 39, 8, 12, 44, 29, 31}\n",
      "{0, 1} {0, 1}\n",
      "{0, 1} {4}\n",
      "{0, 1, 2, 5, 6, 7, 9, 13, 17, 53, 27} {0, 1, 4, 6, 8, 9, 14, 49, 18, 19, 20, 21, 23, 25, 27}\n",
      "{0, 1} {6}\n",
      "{0, 1} {48}\n",
      "{0, 1} {16, 32, 23, 7}\n",
      "{0, 1} {0, 5}\n",
      "{0, 1} {0, 1, 31}\n",
      "{0, 1} {48}\n",
      "{0, 1} {0, 5, 39, 40, 29}\n",
      "{0, 1} {0, 1, 10, 28}\n",
      "{0, 1} {2, 4, 6, 9, 13, 22}\n",
      "{0, 1} {12}\n",
      "{0, 1} {0, 1}\n",
      "{0, 1, 6, 13, 60} {0, 1, 33, 34, 14, 20, 21}\n",
      "{0, 1} {0, 1, 5, 39, 29}\n",
      "{0, 1} {0, 1, 26}\n",
      "{0, 1} {23}\n",
      "{0, 1} {0, 1, 2, 4}\n",
      "{0, 1} {21}\n",
      "{0, 1} {0, 4, 5, 10, 17, 28}\n",
      "{0, 1} {2}\n",
      "{0, 1} {0, 4, 5, 17, 31}\n",
      "{0, 1} {0, 1, 10, 12, 26}\n",
      "{0, 1, 6} {0, 1, 35, 49}\n",
      "{0, 1} set()\n",
      "{0, 1} {0, 4}\n",
      "{0, 1} {0, 5, 10, 11, 43, 17, 28}\n",
      "{0, 1} {0}\n",
      "{0, 1} {21, 4, 5, 52}\n",
      "{0, 1} {16, 4, 5, 7}\n",
      "{0, 1} {22}\n",
      "{0, 1, 6} {0, 1, 39, 40, 29}\n",
      "{0, 1} {0}\n",
      "{0, 1} {0, 1, 4, 5, 13}\n",
      "{0, 1} {0, 1, 39, 8, 12, 15, 29}\n",
      "{0, 1, 6} {0, 1, 2, 42, 14}\n",
      "{0, 1} {0, 1}\n",
      "{0, 1, 2} {0, 1, 2, 4, 6, 9, 20}\n",
      "{0, 1} {0, 4, 31}\n",
      "{0, 1} {2, 5, 22}\n",
      "{0, 1} {0, 34, 8, 14, 20, 26}\n",
      "{0, 1, 6, 13, 17, 24, 60} {0, 1, 4, 36, 37, 7, 8, 39, 42, 50, 23, 29, 31}\n",
      "{0, 1} {2, 21, 5}\n",
      "{0, 1} {0, 1}\n",
      "{0, 1} {5, 54}\n",
      "{0, 1} {50, 59, 52, 21}\n",
      "{0, 1} {1, 5, 11, 17, 23}\n",
      "{0, 1, 11, 17, 24, 60, 31} {0, 1, 7, 41, 11, 46, 16, 49, 19, 20, 21, 25, 27}\n",
      "{0, 1} {17, 10, 28}\n",
      "{0, 1, 6} {0, 1, 7, 8, 16, 26}\n",
      "{0, 1} {0, 1, 39, 50, 56, 58, 29}\n",
      "{0, 1} {0, 1, 2, 34, 6, 8, 19, 21}\n",
      "{0, 1} {0, 1, 4, 5, 7, 8, 47, 16, 17}\n",
      "{0, 1} {0, 1, 33, 35, 11, 14}\n",
      "{0, 1} {10, 42, 37}\n",
      "{0, 1} {48}\n",
      "{0, 1} {4, 5}\n",
      "{0, 1, 6} {0, 1, 39, 8, 15, 29}\n",
      "{0, 1} {0, 1}\n",
      "{0, 1} {0, 1, 2, 4, 6, 39, 8, 29}\n",
      "{0, 1} {48}\n",
      "{0, 1} {2, 4}\n",
      "{0, 1} {0, 1, 2, 4, 6, 19, 20}\n",
      "{0, 1} {10, 34, 13, 6}\n",
      "{0, 1} {17, 10, 28, 5}\n",
      "{0, 1, 6} {0, 1, 39, 10, 50, 56, 58, 29, 31}\n",
      "{0, 1} {0, 4, 14, 17, 18, 23, 31}\n",
      "{0, 1} {0, 1, 15}\n",
      "{0, 1} {8, 29, 39}\n",
      "{0, 1} {0, 2, 4, 6, 10, 13}\n",
      "{0, 1} {0, 1}\n",
      "{0, 1} {21, 5, 54}\n",
      "{0, 1} {0, 1, 29, 39}\n",
      "{0, 1} {12}\n",
      "{0, 1, 13, 5} {0, 1, 2, 5, 8}\n",
      "{0, 1} {0, 1, 5, 8, 31}\n",
      "{0, 1} {0, 1, 8}\n",
      "{0, 1} {12}\n",
      "{0, 1} {4}\n",
      "{0, 1} {2, 13, 19, 21, 27}\n",
      "{0, 1} {0, 6, 39, 50, 56, 58, 29}\n",
      "{0, 1} {57, 36, 5}\n",
      "{0, 1} {0, 1}\n",
      "{0, 1} {12}\n",
      "{0, 1} {5, 21, 54, 28, 31}\n",
      "{0, 1} {48}\n",
      "{0, 1} {10, 52, 5}\n",
      "{0, 1} {0, 2, 29, 39}\n",
      "{0, 1} {0, 1, 12}\n",
      "{0, 1} {0, 1, 2, 12}\n",
      "{0, 1} {0, 1, 32, 5, 23}\n",
      "{0, 1} {2, 4, 6, 31}\n",
      "{0, 1} {34, 12}\n",
      "{0, 1} {0, 1, 26, 15}\n",
      "{0, 1} {10, 28, 5}\n",
      "{0, 1} {8, 2}\n",
      "{0, 1, 6, 13, 60, 31} {0, 33, 2, 6, 11, 13, 14, 18, 20, 23}\n"
     ]
    }
   ],
   "source": [
    "J = np.zeros(100)\n",
    "for i in range(100):\n",
    "    A = set(np.where(pred[i,:]>0.4)[0])\n",
    "    B = set(np.where(y_test[i,:]==1)[0])\n",
    "    J[i] = len(A.intersection(B))/len(A) #/len(A.union(B))\n",
    "    print(A,B) #, pred[i,np.array(list(B))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "A = {1,2}\n",
    "print(np.array(list(A)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
