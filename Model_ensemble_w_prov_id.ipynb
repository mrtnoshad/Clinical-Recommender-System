{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook is the main notebook to run the recommendations of the procedures based on the lab results and diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PC_enc  F0_y_y  F1  F2  F3  F4  F5  F6  F7  F8  ...  F51_y  F52_y  \\\n",
      "4326  16116015       0   0   0   0   0   0   0   0   0  ...      0      0   \n",
      "1525  16175218       0   0   0   0   0   0   0   0   0  ...      0      0   \n",
      "5042  16494386       0   0   0   0   0   0   0   0   0  ...      0      0   \n",
      "5055  16927888       0   0   0   0   0   0   0   0   0  ...      0      0   \n",
      "2418  17091694       1   0   0   0   1   1   0   0   0  ...      0      0   \n",
      "\n",
      "      F53_y  F54_y  F55_y  F56_y  F57_y  F58_y  F59_y  F60_y  \n",
      "4326      0      0      0      0      0      0      0      0  \n",
      "1525      0      0      0      0      0      0      0      0  \n",
      "5042      0      0      0      0      0      0      0      0  \n",
      "5055      0      0      0      0      0      0      0      0  \n",
      "2418      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[5 rows x 62 columns]\n",
      "(5500, 152)\n",
      "(5500, 61)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# trin and test output\n",
    "data_test = pd.read_csv('data_processing/data_test.csv')\n",
    "data_train = pd.read_csv('data_processing/data_train.csv')\n",
    "\n",
    "PC_pr_tr = data_train[[data_train.columns[0]]+ list(data_train.columns[314: 375])].sort_values('PC_enc')\n",
    "PC_pr_ts = data_test[[data_test.columns[0]]+ list(data_test.columns[314: 375])].sort_values('PC_enc')\n",
    "\n",
    "\n",
    "\n",
    "#df_test = pd.read_csv('data/data_test.csv').sort_values('PC_enc')\n",
    "SP_pr_tr = data_train[[data_train.columns[0]]+ list(data_train.columns[407:])].sort_values('PC_enc')\n",
    "SP_pr_ts = data_test[[data_test.columns[0]]+ list(data_test.columns[407:])].sort_values('PC_enc')\n",
    "print(SP_pr_tr.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predictions from model 1 and 2\n",
    "\n",
    "# train set\n",
    "df_model2_train = pd.read_csv('evaluation/data/CF_AE_pred_train.csv').sort_values('PC_enc')\n",
    "df_model1_train = pd.read_csv('evaluation/data/Model1_pred_train.csv').sort_values('PC_enc')\n",
    "#print(df_model1_train.shape)\n",
    "#print(df_model1_train[0])\n",
    "\n",
    "df_model2_train = pd.merge(df_model2_train, df_model1_train['PC_enc'], on='PC_enc', how='inner').sort_values('PC_enc')\n",
    "\n",
    "\n",
    "\n",
    "# test set\n",
    "df_model2_pred = pd.read_csv('evaluation/data/CF_AE_pred.csv').sort_values('PC_enc')\n",
    "df_model1_pred = pd.read_csv('evaluation/data/Model1_pred.csv').sort_values('PC_enc')\n",
    "\n",
    "# privoder information\n",
    "SP_id_tr = data_train[[data_train.columns[0]]+ list(data_train.columns[377: 407])].sort_values('PC_enc')\n",
    "SP_id_ts = data_test[[data_test.columns[0]]+ list(data_test.columns[377: 407])].sort_values('PC_enc')\n",
    "\n",
    "#print(df_model1_train[:10,:])\n",
    "#print(df_model2_train[:10,:])\n",
    "\n",
    "\n",
    "train_joined = pd.merge( df_model2_train, df_model1_train, on='PC_enc', how='inner')\n",
    "X_train = pd.merge( train_joined, SP_id_tr, on='PC_enc', how='inner').to_numpy()[:,1:] # Add prov info\n",
    "\n",
    "#print(train_joined[:10,:])\n",
    "\n",
    "#X_train =  pd.merge(SP_id_tr, df_model1_train, on='PC_enc', how='inner').sort_values('PC_enc').to_numpy()[:,1:]\n",
    "\n",
    "\n",
    "#X_train =  SP_pr_tr.sort_values('PC_enc').to_numpy()[:,1:]\n",
    "#################################\n",
    "\n",
    "\n",
    "test_joined = pd.merge( df_model2_pred, df_model1_pred, on='PC_enc', how='inner')\n",
    "X_test = pd.merge( test_joined, SP_id_ts, on='PC_enc', how='inner').to_numpy()[:,1:] # Add prov info\n",
    "\n",
    "#X_test =   pd.merge(SP_id_ts , df_model1_pred, on='PC_enc', how='inner').sort_values('PC_enc').to_numpy()[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#X_test =   SP_pr_ts.sort_values('PC_enc').to_numpy()[:,1:] \n",
    "\n",
    "\n",
    "#print(X_train.shape)\n",
    "\n",
    "#print(X_train[0])\n",
    "#print(X_test[:10,:])\n",
    "# Only include model 2 as input\n",
    "#X_train = df_model1_train.to_numpy()[:,1:]\n",
    "#X_test = df_model1_pred.to_numpy()[:,1:]\n",
    "\n",
    "\n",
    "Y_train = SP_pr_tr.sort_values('PC_enc').to_numpy()[:,1:]\n",
    "Y_test = SP_pr_ts.sort_values('PC_enc').to_numpy()[:,1:]\n",
    "\n",
    "\n",
    "d = X_train.shape[1]\n",
    "N_train = X_train.shape[0]\n",
    "\n",
    "d_out = Y_train.shape[1]\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "#print(X_train[:10]!=Y_train[:10])\n",
    "#print(X_test[:10]!=Y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311    131240872227\n",
      "1312    131240887260\n",
      "1313    131240890527\n",
      "1314    131240893153\n",
      "1315    131240899094\n",
      "1316    131240966487\n",
      "1317    131241025125\n",
      "1318    131241061358\n",
      "1319    131241077737\n",
      "1320    131261087497\n",
      "Name: PC_enc, dtype: int64\n",
      "907     131240872227\n",
      "906     131240887260\n",
      "893     131240890527\n",
      "870     131240893153\n",
      "879     131240899094\n",
      "874     131240966487\n",
      "889     131241025125\n",
      "886     131241061358\n",
      "884     131241077737\n",
      "1320    131261087497\n",
      "Name: PC_enc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## test and debug: REMOVE LATER\n",
    "print(pd.merge(df_model1_pred, df_model2_pred, on='PC_enc', how='inner').PC_enc.tail(10))\n",
    "print(SP_pr_ts.PC_enc.tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll start simple, with a single fully-connected neural layer as encoder and as decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "#input_img = Input(shape=(d,))\n",
    "#encoded = Dense(100, activation='relu')(input_img)\n",
    "#decoded = Dense(d_out, activation='relu')(encoded)\n",
    "p = 0.35 # dropout\n",
    "\n",
    "input_img = Input(shape=(d,))\n",
    "encoded = Dense(200, activation='relu')(input_img)\n",
    "encoded = Dropout(rate=p)(encoded)\n",
    "encoded = Dense(150, activation='relu')(encoded)\n",
    "encoded = Dropout(rate=p)(encoded)\n",
    "encoded = Dense(100, activation='relu')(encoded)\n",
    "encoded = Dropout(rate=p)(encoded)\n",
    "#encoded = Dense(80, activation='relu')(encoded)\n",
    "#encoded = Dropout(rate=p)(encoded)\n",
    "encoded = Dense(80, activation='relu')(encoded)\n",
    "encoded = Dropout(rate=p)(encoded)\n",
    "decoded = Dense(d_out, activation='relu')(encoded)\n",
    "\n",
    "#encoding_dim = 40\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's train our autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "#opt = keras.optimizers.SGD(lr=9e-2, momentum=0.9, decay=1e-2/100)\n",
    "sgd = keras.optimizers.SGD(lr=0.05, decay=1e-5, momentum=0.9) #(lr=0.03, decay=1e-6, momentum=0.9)\n",
    "#sgd=keras.optimizers.Adam(learning_rate=0.01)\n",
    "autoencoder.compile(optimizer=sgd, loss = 'mean_squared_error') #loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's train our autoencoder for 50 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500 samples, validate on 1321 samples\n",
      "Epoch 1/450\n",
      "5500/5500 [==============================] - 0s 41us/step - loss: 0.0702 - val_loss: 0.0685\n",
      "Epoch 2/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0653 - val_loss: 0.0639\n",
      "Epoch 3/450\n",
      "5500/5500 [==============================] - 0s 21us/step - loss: 0.0614 - val_loss: 0.0606\n",
      "Epoch 4/450\n",
      "5500/5500 [==============================] - 0s 21us/step - loss: 0.0592 - val_loss: 0.0593\n",
      "Epoch 5/450\n",
      "5500/5500 [==============================] - 0s 18us/step - loss: 0.0583 - val_loss: 0.0589\n",
      "Epoch 6/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0578 - val_loss: 0.0586\n",
      "Epoch 7/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0575 - val_loss: 0.0584\n",
      "Epoch 8/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0573 - val_loss: 0.0582\n",
      "Epoch 9/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0571 - val_loss: 0.0581\n",
      "Epoch 10/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0569 - val_loss: 0.0580\n",
      "Epoch 11/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0568 - val_loss: 0.0580\n",
      "Epoch 12/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0567 - val_loss: 0.0579\n",
      "Epoch 13/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0567 - val_loss: 0.0578\n",
      "Epoch 14/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0565 - val_loss: 0.0578\n",
      "Epoch 15/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0565 - val_loss: 0.0578\n",
      "Epoch 16/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0565 - val_loss: 0.0577\n",
      "Epoch 17/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0564 - val_loss: 0.0577\n",
      "Epoch 18/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0564 - val_loss: 0.0577\n",
      "Epoch 19/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0563 - val_loss: 0.0577\n",
      "Epoch 20/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0563 - val_loss: 0.0577\n",
      "Epoch 21/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0563 - val_loss: 0.0576\n",
      "Epoch 22/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0563 - val_loss: 0.0576\n",
      "Epoch 23/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0562 - val_loss: 0.0576\n",
      "Epoch 24/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0562 - val_loss: 0.0576\n",
      "Epoch 25/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0562 - val_loss: 0.0576\n",
      "Epoch 26/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0562 - val_loss: 0.0576\n",
      "Epoch 27/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0561 - val_loss: 0.0576\n",
      "Epoch 28/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0561 - val_loss: 0.0576\n",
      "Epoch 29/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0561 - val_loss: 0.0576\n",
      "Epoch 30/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0561 - val_loss: 0.0576\n",
      "Epoch 31/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0560 - val_loss: 0.0576\n",
      "Epoch 32/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0560 - val_loss: 0.0576\n",
      "Epoch 33/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0560 - val_loss: 0.0576\n",
      "Epoch 34/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0560 - val_loss: 0.0576\n",
      "Epoch 35/450\n",
      "5500/5500 [==============================] - 0s 22us/step - loss: 0.0559 - val_loss: 0.0576\n",
      "Epoch 36/450\n",
      "5500/5500 [==============================] - 0s 19us/step - loss: 0.0559 - val_loss: 0.0576\n",
      "Epoch 37/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0559 - val_loss: 0.0576\n",
      "Epoch 38/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0559 - val_loss: 0.0576\n",
      "Epoch 39/450\n",
      "5500/5500 [==============================] - 0s 18us/step - loss: 0.0559 - val_loss: 0.0577\n",
      "Epoch 40/450\n",
      "5500/5500 [==============================] - 0s 20us/step - loss: 0.0558 - val_loss: 0.0576\n",
      "Epoch 41/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0558 - val_loss: 0.0577\n",
      "Epoch 42/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0558 - val_loss: 0.0577\n",
      "Epoch 43/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0558 - val_loss: 0.0577\n",
      "Epoch 44/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0557 - val_loss: 0.0577\n",
      "Epoch 45/450\n",
      "5500/5500 [==============================] - 0s 19us/step - loss: 0.0556 - val_loss: 0.0577\n",
      "Epoch 46/450\n",
      "5500/5500 [==============================] - 0s 18us/step - loss: 0.0557 - val_loss: 0.0577\n",
      "Epoch 47/450\n",
      "5500/5500 [==============================] - 0s 22us/step - loss: 0.0556 - val_loss: 0.0578\n",
      "Epoch 48/450\n",
      "5500/5500 [==============================] - 0s 27us/step - loss: 0.0556 - val_loss: 0.0578\n",
      "Epoch 49/450\n",
      "5500/5500 [==============================] - 0s 27us/step - loss: 0.0556 - val_loss: 0.0578\n",
      "Epoch 50/450\n",
      "5500/5500 [==============================] - 0s 29us/step - loss: 0.0556 - val_loss: 0.0578\n",
      "Epoch 51/450\n",
      "5500/5500 [==============================] - 0s 24us/step - loss: 0.0554 - val_loss: 0.0578\n",
      "Epoch 52/450\n",
      "5500/5500 [==============================] - 0s 24us/step - loss: 0.0554 - val_loss: 0.0579\n",
      "Epoch 53/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0554 - val_loss: 0.0579\n",
      "Epoch 54/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0553 - val_loss: 0.0579\n",
      "Epoch 55/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0553 - val_loss: 0.0580\n",
      "Epoch 56/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0552 - val_loss: 0.0580\n",
      "Epoch 57/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0552 - val_loss: 0.0580\n",
      "Epoch 58/450\n",
      "5500/5500 [==============================] - 0s 25us/step - loss: 0.0552 - val_loss: 0.0581\n",
      "Epoch 59/450\n",
      "5500/5500 [==============================] - 0s 24us/step - loss: 0.0552 - val_loss: 0.0581\n",
      "Epoch 60/450\n",
      "5500/5500 [==============================] - 0s 24us/step - loss: 0.0551 - val_loss: 0.0581\n",
      "Epoch 61/450\n",
      "5500/5500 [==============================] - 0s 23us/step - loss: 0.0551 - val_loss: 0.0582\n",
      "Epoch 62/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0550 - val_loss: 0.0582\n",
      "Epoch 63/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0549 - val_loss: 0.0583\n",
      "Epoch 64/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0549 - val_loss: 0.0583\n",
      "Epoch 65/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0548 - val_loss: 0.0584\n",
      "Epoch 66/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0548 - val_loss: 0.0584\n",
      "Epoch 67/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0547 - val_loss: 0.0585\n",
      "Epoch 68/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0547 - val_loss: 0.0585\n",
      "Epoch 69/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0546 - val_loss: 0.0586\n",
      "Epoch 70/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0545 - val_loss: 0.0587\n",
      "Epoch 71/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0545 - val_loss: 0.0587\n",
      "Epoch 72/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0544 - val_loss: 0.0588\n",
      "Epoch 73/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0543 - val_loss: 0.0589\n",
      "Epoch 74/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0543 - val_loss: 0.0589\n",
      "Epoch 75/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0543 - val_loss: 0.0590\n",
      "Epoch 76/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0542 - val_loss: 0.0591\n",
      "Epoch 77/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0542 - val_loss: 0.0591\n",
      "Epoch 78/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0541 - val_loss: 0.0592\n",
      "Epoch 79/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0541 - val_loss: 0.0593\n",
      "Epoch 80/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0539 - val_loss: 0.0594\n",
      "Epoch 81/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0540 - val_loss: 0.0594\n",
      "Epoch 82/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0540 - val_loss: 0.0595\n",
      "Epoch 83/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0538 - val_loss: 0.0596\n",
      "Epoch 84/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0538 - val_loss: 0.0597\n",
      "Epoch 85/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0538 - val_loss: 0.0597\n",
      "Epoch 86/450\n",
      "5500/5500 [==============================] - 0s 21us/step - loss: 0.0538 - val_loss: 0.0598\n",
      "Epoch 87/450\n",
      "5500/5500 [==============================] - 0s 24us/step - loss: 0.0537 - val_loss: 0.0599\n",
      "Epoch 88/450\n",
      "5500/5500 [==============================] - 0s 22us/step - loss: 0.0537 - val_loss: 0.0599\n",
      "Epoch 89/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0536 - val_loss: 0.0600\n",
      "Epoch 90/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0536 - val_loss: 0.0601\n",
      "Epoch 91/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0535 - val_loss: 0.0601\n",
      "Epoch 92/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0534 - val_loss: 0.0603\n",
      "Epoch 93/450\n",
      "5500/5500 [==============================] - 0s 20us/step - loss: 0.0534 - val_loss: 0.0603\n",
      "Epoch 94/450\n",
      "5500/5500 [==============================] - 0s 20us/step - loss: 0.0534 - val_loss: 0.0604\n",
      "Epoch 95/450\n",
      "5500/5500 [==============================] - 0s 20us/step - loss: 0.0534 - val_loss: 0.0604\n",
      "Epoch 96/450\n",
      "5500/5500 [==============================] - 0s 18us/step - loss: 0.0534 - val_loss: 0.0605\n",
      "Epoch 97/450\n",
      "5500/5500 [==============================] - 0s 23us/step - loss: 0.0533 - val_loss: 0.0606\n",
      "Epoch 98/450\n",
      "5500/5500 [==============================] - 0s 23us/step - loss: 0.0532 - val_loss: 0.0606\n",
      "Epoch 99/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0533 - val_loss: 0.0607\n",
      "Epoch 100/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0531 - val_loss: 0.0608\n",
      "Epoch 101/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0531 - val_loss: 0.0608\n",
      "Epoch 102/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0531 - val_loss: 0.0609\n",
      "Epoch 103/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0530 - val_loss: 0.0610\n",
      "Epoch 104/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0531 - val_loss: 0.0610\n",
      "Epoch 105/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0530 - val_loss: 0.0611\n",
      "Epoch 106/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0530 - val_loss: 0.0612\n",
      "Epoch 107/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0529 - val_loss: 0.0612\n",
      "Epoch 108/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0529 - val_loss: 0.0612\n",
      "Epoch 109/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0529 - val_loss: 0.0613\n",
      "Epoch 110/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0529 - val_loss: 0.0614\n",
      "Epoch 111/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0528 - val_loss: 0.0615\n",
      "Epoch 112/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0528 - val_loss: 0.0615\n",
      "Epoch 113/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0527 - val_loss: 0.0616\n",
      "Epoch 114/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0528 - val_loss: 0.0616\n",
      "Epoch 115/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0528 - val_loss: 0.0617\n",
      "Epoch 116/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0527 - val_loss: 0.0617\n",
      "Epoch 117/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0527 - val_loss: 0.0618\n",
      "Epoch 118/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0525 - val_loss: 0.0619\n",
      "Epoch 119/450\n",
      "5500/5500 [==============================] - 0s 18us/step - loss: 0.0527 - val_loss: 0.0619\n",
      "Epoch 120/450\n",
      "5500/5500 [==============================] - 0s 18us/step - loss: 0.0525 - val_loss: 0.0619\n",
      "Epoch 121/450\n",
      "5500/5500 [==============================] - 0s 21us/step - loss: 0.0526 - val_loss: 0.0619\n",
      "Epoch 122/450\n",
      "5500/5500 [==============================] - 0s 22us/step - loss: 0.0524 - val_loss: 0.0620\n",
      "Epoch 123/450\n",
      "5500/5500 [==============================] - 0s 22us/step - loss: 0.0524 - val_loss: 0.0621\n",
      "Epoch 124/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0525 - val_loss: 0.0621\n",
      "Epoch 125/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0523 - val_loss: 0.0622\n",
      "Epoch 126/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0524 - val_loss: 0.0623\n",
      "Epoch 127/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0523 - val_loss: 0.0622\n",
      "Epoch 128/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0524 - val_loss: 0.0623\n",
      "Epoch 129/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0523 - val_loss: 0.0624\n",
      "Epoch 130/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0523 - val_loss: 0.0624\n",
      "Epoch 131/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0522 - val_loss: 0.0625\n",
      "Epoch 132/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0522 - val_loss: 0.0625\n",
      "Epoch 133/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0521 - val_loss: 0.0625\n",
      "Epoch 134/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0521 - val_loss: 0.0627\n",
      "Epoch 135/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0520 - val_loss: 0.0627\n",
      "Epoch 136/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0520 - val_loss: 0.0627\n",
      "Epoch 137/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0521 - val_loss: 0.0627\n",
      "Epoch 138/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0520 - val_loss: 0.0628\n",
      "Epoch 139/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0521 - val_loss: 0.0628\n",
      "Epoch 140/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0520 - val_loss: 0.0629\n",
      "Epoch 141/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0520 - val_loss: 0.0629\n",
      "Epoch 142/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0520 - val_loss: 0.0629\n",
      "Epoch 143/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0519 - val_loss: 0.0629\n",
      "Epoch 144/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0519 - val_loss: 0.0630\n",
      "Epoch 145/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0519 - val_loss: 0.0631\n",
      "Epoch 146/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0518 - val_loss: 0.0631\n",
      "Epoch 147/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0519 - val_loss: 0.0632\n",
      "Epoch 148/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0518 - val_loss: 0.0633\n",
      "Epoch 149/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0518 - val_loss: 0.0633\n",
      "Epoch 150/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0517 - val_loss: 0.0633\n",
      "Epoch 151/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0518 - val_loss: 0.0633\n",
      "Epoch 152/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0516 - val_loss: 0.0633\n",
      "Epoch 153/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0517 - val_loss: 0.0634\n",
      "Epoch 154/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0516 - val_loss: 0.0634\n",
      "Epoch 155/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0516 - val_loss: 0.0636\n",
      "Epoch 156/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0517 - val_loss: 0.0635\n",
      "Epoch 157/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0516 - val_loss: 0.0635\n",
      "Epoch 158/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0516 - val_loss: 0.0636\n",
      "Epoch 159/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0514 - val_loss: 0.0636\n",
      "Epoch 160/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0516 - val_loss: 0.0637\n",
      "Epoch 161/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0515 - val_loss: 0.0636\n",
      "Epoch 162/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0514 - val_loss: 0.0636\n",
      "Epoch 163/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0513 - val_loss: 0.0637\n",
      "Epoch 164/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0515 - val_loss: 0.0637\n",
      "Epoch 165/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0514 - val_loss: 0.0637\n",
      "Epoch 166/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0514 - val_loss: 0.0637\n",
      "Epoch 167/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0514 - val_loss: 0.0637\n",
      "Epoch 168/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0513 - val_loss: 0.0639\n",
      "Epoch 169/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0512 - val_loss: 0.0639\n",
      "Epoch 170/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0513 - val_loss: 0.0638\n",
      "Epoch 171/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0512 - val_loss: 0.0639\n",
      "Epoch 172/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0512 - val_loss: 0.0638\n",
      "Epoch 173/450\n",
      "5500/5500 [==============================] - 0s 19us/step - loss: 0.0512 - val_loss: 0.0640\n",
      "Epoch 174/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0512 - val_loss: 0.0639\n",
      "Epoch 175/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0512 - val_loss: 0.0639\n",
      "Epoch 176/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0510 - val_loss: 0.0639\n",
      "Epoch 177/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0511 - val_loss: 0.0640\n",
      "Epoch 178/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0511 - val_loss: 0.0639\n",
      "Epoch 179/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0510 - val_loss: 0.0641\n",
      "Epoch 180/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0509 - val_loss: 0.0641\n",
      "Epoch 181/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0509 - val_loss: 0.0641\n",
      "Epoch 182/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0510 - val_loss: 0.0641\n",
      "Epoch 183/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0510 - val_loss: 0.0641\n",
      "Epoch 184/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0509 - val_loss: 0.0641\n",
      "Epoch 185/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0510 - val_loss: 0.0642\n",
      "Epoch 186/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0509 - val_loss: 0.0643\n",
      "Epoch 187/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0510 - val_loss: 0.0642\n",
      "Epoch 188/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0508 - val_loss: 0.0645\n",
      "Epoch 189/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0508 - val_loss: 0.0644\n",
      "Epoch 190/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0508 - val_loss: 0.0644\n",
      "Epoch 191/450\n",
      "5500/5500 [==============================] - 0s 19us/step - loss: 0.0508 - val_loss: 0.0644\n",
      "Epoch 192/450\n",
      "5500/5500 [==============================] - 0s 22us/step - loss: 0.0508 - val_loss: 0.0644\n",
      "Epoch 193/450\n",
      "5500/5500 [==============================] - 0s 24us/step - loss: 0.0508 - val_loss: 0.0644\n",
      "Epoch 194/450\n",
      "5500/5500 [==============================] - 0s 18us/step - loss: 0.0508 - val_loss: 0.0645\n",
      "Epoch 195/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0507 - val_loss: 0.0644\n",
      "Epoch 196/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0507 - val_loss: 0.0645\n",
      "Epoch 197/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0506 - val_loss: 0.0645\n",
      "Epoch 198/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0507 - val_loss: 0.0646\n",
      "Epoch 199/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0507 - val_loss: 0.0646\n",
      "Epoch 200/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0508 - val_loss: 0.0646\n",
      "Epoch 201/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0507 - val_loss: 0.0645\n",
      "Epoch 202/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0506 - val_loss: 0.0646\n",
      "Epoch 203/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0505 - val_loss: 0.0647\n",
      "Epoch 204/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0505 - val_loss: 0.0646\n",
      "Epoch 205/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0506 - val_loss: 0.0646\n",
      "Epoch 206/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0505 - val_loss: 0.0648\n",
      "Epoch 207/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0506 - val_loss: 0.0645\n",
      "Epoch 208/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0505 - val_loss: 0.0646\n",
      "Epoch 209/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0504 - val_loss: 0.0647\n",
      "Epoch 210/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0505 - val_loss: 0.0648\n",
      "Epoch 211/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0505 - val_loss: 0.0647\n",
      "Epoch 212/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0504 - val_loss: 0.0649\n",
      "Epoch 213/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0505 - val_loss: 0.0647\n",
      "Epoch 214/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0505 - val_loss: 0.0647\n",
      "Epoch 215/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0504 - val_loss: 0.0649\n",
      "Epoch 216/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0503 - val_loss: 0.0649\n",
      "Epoch 217/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0504 - val_loss: 0.0650\n",
      "Epoch 218/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0504 - val_loss: 0.0648\n",
      "Epoch 219/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0504 - val_loss: 0.0650\n",
      "Epoch 220/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0503 - val_loss: 0.0649\n",
      "Epoch 221/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0504 - val_loss: 0.0649\n",
      "Epoch 222/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0503 - val_loss: 0.0649\n",
      "Epoch 223/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0502 - val_loss: 0.0650\n",
      "Epoch 224/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0502 - val_loss: 0.0651\n",
      "Epoch 225/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0502 - val_loss: 0.0650\n",
      "Epoch 226/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0502 - val_loss: 0.0652\n",
      "Epoch 227/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0501 - val_loss: 0.0651\n",
      "Epoch 228/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0502 - val_loss: 0.0651\n",
      "Epoch 229/450\n",
      "5500/5500 [==============================] - 0s 18us/step - loss: 0.0502 - val_loss: 0.0651\n",
      "Epoch 230/450\n",
      "5500/5500 [==============================] - 0s 20us/step - loss: 0.0502 - val_loss: 0.0651\n",
      "Epoch 231/450\n",
      "5500/5500 [==============================] - 0s 20us/step - loss: 0.0503 - val_loss: 0.0651\n",
      "Epoch 232/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500/5500 [==============================] - 0s 23us/step - loss: 0.0501 - val_loss: 0.0652\n",
      "Epoch 233/450\n",
      "5500/5500 [==============================] - 0s 25us/step - loss: 0.0502 - val_loss: 0.0653\n",
      "Epoch 234/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0501 - val_loss: 0.0652\n",
      "Epoch 235/450\n",
      "5500/5500 [==============================] - 0s 26us/step - loss: 0.0500 - val_loss: 0.0653\n",
      "Epoch 236/450\n",
      "5500/5500 [==============================] - 0s 24us/step - loss: 0.0501 - val_loss: 0.0652\n",
      "Epoch 237/450\n",
      "5500/5500 [==============================] - 0s 19us/step - loss: 0.0501 - val_loss: 0.0653\n",
      "Epoch 238/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0501 - val_loss: 0.0652\n",
      "Epoch 239/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0500 - val_loss: 0.0652\n",
      "Epoch 240/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0499 - val_loss: 0.0653\n",
      "Epoch 241/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0502 - val_loss: 0.0653\n",
      "Epoch 242/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0500 - val_loss: 0.0653\n",
      "Epoch 243/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0501 - val_loss: 0.0654\n",
      "Epoch 244/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0499 - val_loss: 0.0653\n",
      "Epoch 245/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0500 - val_loss: 0.0655\n",
      "Epoch 246/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0500 - val_loss: 0.0654\n",
      "Epoch 247/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0499 - val_loss: 0.0655\n",
      "Epoch 248/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0500 - val_loss: 0.0655\n",
      "Epoch 249/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0499 - val_loss: 0.0655\n",
      "Epoch 250/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0499 - val_loss: 0.0654\n",
      "Epoch 251/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0500 - val_loss: 0.0655\n",
      "Epoch 252/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0498 - val_loss: 0.0654\n",
      "Epoch 253/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0499 - val_loss: 0.0654\n",
      "Epoch 254/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0499 - val_loss: 0.0655\n",
      "Epoch 255/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0499 - val_loss: 0.0655\n",
      "Epoch 256/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0498 - val_loss: 0.0657\n",
      "Epoch 257/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0498 - val_loss: 0.0656\n",
      "Epoch 258/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0499 - val_loss: 0.0656\n",
      "Epoch 259/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0498 - val_loss: 0.0658\n",
      "Epoch 260/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0498 - val_loss: 0.0657\n",
      "Epoch 261/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0498 - val_loss: 0.0656\n",
      "Epoch 262/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0499 - val_loss: 0.0656\n",
      "Epoch 263/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0497 - val_loss: 0.0656\n",
      "Epoch 264/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0498 - val_loss: 0.0656\n",
      "Epoch 265/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0497 - val_loss: 0.0657\n",
      "Epoch 266/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0498 - val_loss: 0.0658\n",
      "Epoch 267/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0497 - val_loss: 0.0657\n",
      "Epoch 268/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0497 - val_loss: 0.0657\n",
      "Epoch 269/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0497 - val_loss: 0.0657\n",
      "Epoch 270/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0496 - val_loss: 0.0658\n",
      "Epoch 271/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0496 - val_loss: 0.0658\n",
      "Epoch 272/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0497 - val_loss: 0.0658\n",
      "Epoch 273/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0498 - val_loss: 0.0657\n",
      "Epoch 274/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0496 - val_loss: 0.0659\n",
      "Epoch 275/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0497 - val_loss: 0.0659\n",
      "Epoch 276/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0497 - val_loss: 0.0658\n",
      "Epoch 277/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0496 - val_loss: 0.0659\n",
      "Epoch 278/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0496 - val_loss: 0.0658\n",
      "Epoch 279/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0496 - val_loss: 0.0658\n",
      "Epoch 280/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0497 - val_loss: 0.0659\n",
      "Epoch 281/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0496 - val_loss: 0.0659\n",
      "Epoch 282/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0496 - val_loss: 0.0658\n",
      "Epoch 283/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0496 - val_loss: 0.0659\n",
      "Epoch 284/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0496 - val_loss: 0.0659\n",
      "Epoch 285/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0496 - val_loss: 0.0658\n",
      "Epoch 286/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0495 - val_loss: 0.0659\n",
      "Epoch 287/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0496 - val_loss: 0.0659\n",
      "Epoch 288/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0495 - val_loss: 0.0659\n",
      "Epoch 289/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0496 - val_loss: 0.0658\n",
      "Epoch 290/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0495 - val_loss: 0.0659\n",
      "Epoch 291/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0495 - val_loss: 0.0660\n",
      "Epoch 292/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0495 - val_loss: 0.0662\n",
      "Epoch 293/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0496 - val_loss: 0.0660\n",
      "Epoch 294/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0495 - val_loss: 0.0660\n",
      "Epoch 295/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0495 - val_loss: 0.0660\n",
      "Epoch 296/450\n",
      "5500/5500 [==============================] - 0s 21us/step - loss: 0.0495 - val_loss: 0.0659\n",
      "Epoch 297/450\n",
      "5500/5500 [==============================] - 0s 18us/step - loss: 0.0495 - val_loss: 0.0660\n",
      "Epoch 298/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0494 - val_loss: 0.0660\n",
      "Epoch 299/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0494 - val_loss: 0.0660\n",
      "Epoch 300/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0495 - val_loss: 0.0660\n",
      "Epoch 301/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0493 - val_loss: 0.0660\n",
      "Epoch 302/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0494 - val_loss: 0.0661\n",
      "Epoch 303/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0494 - val_loss: 0.0661\n",
      "Epoch 304/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0494 - val_loss: 0.0660\n",
      "Epoch 305/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0493 - val_loss: 0.0661\n",
      "Epoch 306/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0493 - val_loss: 0.0660\n",
      "Epoch 307/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0494 - val_loss: 0.0661\n",
      "Epoch 308/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0495 - val_loss: 0.0661\n",
      "Epoch 309/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0494 - val_loss: 0.0660\n",
      "Epoch 310/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0493 - val_loss: 0.0662\n",
      "Epoch 311/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0493 - val_loss: 0.0660\n",
      "Epoch 312/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0493 - val_loss: 0.0661\n",
      "Epoch 313/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0493 - val_loss: 0.0661\n",
      "Epoch 314/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0494 - val_loss: 0.0661\n",
      "Epoch 315/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0493 - val_loss: 0.0662\n",
      "Epoch 316/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0493 - val_loss: 0.0661\n",
      "Epoch 317/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0493 - val_loss: 0.0662\n",
      "Epoch 318/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0493 - val_loss: 0.0662\n",
      "Epoch 319/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0493 - val_loss: 0.0662\n",
      "Epoch 320/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0492 - val_loss: 0.0661\n",
      "Epoch 321/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0493 - val_loss: 0.0663\n",
      "Epoch 322/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0493 - val_loss: 0.0661\n",
      "Epoch 323/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0492 - val_loss: 0.0663\n",
      "Epoch 324/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0492 - val_loss: 0.0662\n",
      "Epoch 325/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0492 - val_loss: 0.0663\n",
      "Epoch 326/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0491 - val_loss: 0.0663\n",
      "Epoch 327/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0492 - val_loss: 0.0663\n",
      "Epoch 328/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0494 - val_loss: 0.0662\n",
      "Epoch 329/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0492 - val_loss: 0.0663\n",
      "Epoch 330/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0492 - val_loss: 0.0665\n",
      "Epoch 331/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0491 - val_loss: 0.0664\n",
      "Epoch 332/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0492 - val_loss: 0.0663\n",
      "Epoch 333/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0490 - val_loss: 0.0664\n",
      "Epoch 334/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0491 - val_loss: 0.0663\n",
      "Epoch 335/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0492 - val_loss: 0.0664\n",
      "Epoch 336/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0492 - val_loss: 0.0664\n",
      "Epoch 337/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0492 - val_loss: 0.0664\n",
      "Epoch 338/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0491 - val_loss: 0.0663\n",
      "Epoch 339/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0491 - val_loss: 0.0664\n",
      "Epoch 340/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0491 - val_loss: 0.0664\n",
      "Epoch 341/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0491 - val_loss: 0.0664\n",
      "Epoch 342/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0492 - val_loss: 0.0665\n",
      "Epoch 343/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0490 - val_loss: 0.0665\n",
      "Epoch 344/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0492 - val_loss: 0.0664\n",
      "Epoch 345/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0491 - val_loss: 0.0663\n",
      "Epoch 346/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0490 - val_loss: 0.0665\n",
      "Epoch 347/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0489 - val_loss: 0.0666\n",
      "Epoch 348/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0490 - val_loss: 0.0665\n",
      "Epoch 349/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0490 - val_loss: 0.0666\n",
      "Epoch 350/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0491 - val_loss: 0.0666\n",
      "Epoch 351/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0490 - val_loss: 0.0666\n",
      "Epoch 352/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0490 - val_loss: 0.0665\n",
      "Epoch 353/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0489 - val_loss: 0.0665\n",
      "Epoch 354/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0490 - val_loss: 0.0666\n",
      "Epoch 355/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0490 - val_loss: 0.0664\n",
      "Epoch 356/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0488 - val_loss: 0.0665\n",
      "Epoch 357/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0489 - val_loss: 0.0664\n",
      "Epoch 358/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0489 - val_loss: 0.0666\n",
      "Epoch 359/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0489 - val_loss: 0.0666\n",
      "Epoch 360/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0490 - val_loss: 0.0666\n",
      "Epoch 361/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0491 - val_loss: 0.0665\n",
      "Epoch 362/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0490 - val_loss: 0.0666\n",
      "Epoch 363/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0488 - val_loss: 0.0666\n",
      "Epoch 364/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0489 - val_loss: 0.0665\n",
      "Epoch 365/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0489 - val_loss: 0.0666\n",
      "Epoch 366/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0488 - val_loss: 0.0666\n",
      "Epoch 367/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0490 - val_loss: 0.0666\n",
      "Epoch 368/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0489 - val_loss: 0.0667\n",
      "Epoch 369/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0489 - val_loss: 0.0665\n",
      "Epoch 370/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0489 - val_loss: 0.0666\n",
      "Epoch 371/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0488 - val_loss: 0.0667\n",
      "Epoch 372/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0488 - val_loss: 0.0666\n",
      "Epoch 373/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0489 - val_loss: 0.0667\n",
      "Epoch 374/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0489 - val_loss: 0.0666\n",
      "Epoch 375/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0489 - val_loss: 0.0666\n",
      "Epoch 376/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0489 - val_loss: 0.0665\n",
      "Epoch 377/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0488 - val_loss: 0.0666\n",
      "Epoch 378/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0487 - val_loss: 0.0666\n",
      "Epoch 379/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0489 - val_loss: 0.0666\n",
      "Epoch 380/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0488 - val_loss: 0.0667\n",
      "Epoch 381/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0488 - val_loss: 0.0666\n",
      "Epoch 382/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0488 - val_loss: 0.0666\n",
      "Epoch 383/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0487 - val_loss: 0.0666\n",
      "Epoch 384/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0489 - val_loss: 0.0666\n",
      "Epoch 385/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0489 - val_loss: 0.0667\n",
      "Epoch 386/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0488 - val_loss: 0.0666\n",
      "Epoch 387/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0488 - val_loss: 0.0666\n",
      "Epoch 388/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0488 - val_loss: 0.0668\n",
      "Epoch 389/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0489 - val_loss: 0.0668\n",
      "Epoch 390/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0488 - val_loss: 0.0667\n",
      "Epoch 391/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0487 - val_loss: 0.0667\n",
      "Epoch 392/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0488 - val_loss: 0.0668\n",
      "Epoch 393/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0487 - val_loss: 0.0667\n",
      "Epoch 394/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0487 - val_loss: 0.0668\n",
      "Epoch 395/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0487 - val_loss: 0.0667\n",
      "Epoch 396/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0487 - val_loss: 0.0667\n",
      "Epoch 397/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0487 - val_loss: 0.0667\n",
      "Epoch 398/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0488 - val_loss: 0.0668\n",
      "Epoch 399/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0487 - val_loss: 0.0667\n",
      "Epoch 400/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0488 - val_loss: 0.0666\n",
      "Epoch 401/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0486 - val_loss: 0.0668\n",
      "Epoch 402/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0486 - val_loss: 0.0668\n",
      "Epoch 403/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0486 - val_loss: 0.0667\n",
      "Epoch 404/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0486 - val_loss: 0.0668\n",
      "Epoch 405/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0486 - val_loss: 0.0668\n",
      "Epoch 406/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0487 - val_loss: 0.0668\n",
      "Epoch 407/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0486 - val_loss: 0.0667\n",
      "Epoch 408/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0486 - val_loss: 0.0667\n",
      "Epoch 409/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0486 - val_loss: 0.0668\n",
      "Epoch 410/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0488 - val_loss: 0.0667\n",
      "Epoch 411/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0486 - val_loss: 0.0667\n",
      "Epoch 412/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0486 - val_loss: 0.0667\n",
      "Epoch 413/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0486 - val_loss: 0.0667\n",
      "Epoch 414/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0486 - val_loss: 0.0668\n",
      "Epoch 415/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0486 - val_loss: 0.0668\n",
      "Epoch 416/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0485 - val_loss: 0.0669\n",
      "Epoch 417/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0485 - val_loss: 0.0668\n",
      "Epoch 418/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0484 - val_loss: 0.0668\n",
      "Epoch 419/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0486 - val_loss: 0.0669\n",
      "Epoch 420/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0485 - val_loss: 0.0669\n",
      "Epoch 421/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0486 - val_loss: 0.0668\n",
      "Epoch 422/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0485 - val_loss: 0.0667\n",
      "Epoch 423/450\n",
      "5500/5500 [==============================] - 0s 16us/step - loss: 0.0485 - val_loss: 0.0668\n",
      "Epoch 424/450\n",
      "5500/5500 [==============================] - 0s 17us/step - loss: 0.0485 - val_loss: 0.0667\n",
      "Epoch 425/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0486 - val_loss: 0.0668\n",
      "Epoch 426/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0486 - val_loss: 0.0668\n",
      "Epoch 427/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0484 - val_loss: 0.0668\n",
      "Epoch 428/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0485 - val_loss: 0.0667\n",
      "Epoch 429/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0485 - val_loss: 0.0668\n",
      "Epoch 430/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0483 - val_loss: 0.0668\n",
      "Epoch 431/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0486 - val_loss: 0.0668\n",
      "Epoch 432/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0484 - val_loss: 0.0668\n",
      "Epoch 433/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0485 - val_loss: 0.0668\n",
      "Epoch 434/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0486 - val_loss: 0.0668\n",
      "Epoch 435/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0484 - val_loss: 0.0669\n",
      "Epoch 436/450\n",
      "5500/5500 [==============================] - 0s 18us/step - loss: 0.0485 - val_loss: 0.0668\n",
      "Epoch 437/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0484 - val_loss: 0.0668\n",
      "Epoch 438/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0484 - val_loss: 0.0669\n",
      "Epoch 439/450\n",
      "5500/5500 [==============================] - 0s 15us/step - loss: 0.0485 - val_loss: 0.0668\n",
      "Epoch 440/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0484 - val_loss: 0.0668\n",
      "Epoch 441/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0485 - val_loss: 0.0667\n",
      "Epoch 442/450\n",
      "5500/5500 [==============================] - 0s 13us/step - loss: 0.0485 - val_loss: 0.0669\n",
      "Epoch 443/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0484 - val_loss: 0.0668\n",
      "Epoch 444/450\n",
      "5500/5500 [==============================] - 0s 14us/step - loss: 0.0485 - val_loss: 0.0668\n",
      "Epoch 445/450\n",
      "5500/5500 [==============================] - 0s 20us/step - loss: 0.0484 - val_loss: 0.0668\n",
      "Epoch 446/450\n",
      "5500/5500 [==============================] - 0s 19us/step - loss: 0.0483 - val_loss: 0.0669\n",
      "Epoch 447/450\n",
      "5500/5500 [==============================] - 0s 22us/step - loss: 0.0484 - val_loss: 0.0668\n",
      "Epoch 448/450\n",
      "5500/5500 [==============================] - 0s 24us/step - loss: 0.0484 - val_loss: 0.0669\n",
      "Epoch 449/450\n",
      "5500/5500 [==============================] - 0s 25us/step - loss: 0.0485 - val_loss: 0.0669\n",
      "Epoch 450/450\n",
      "5500/5500 [==============================] - 0s 22us/step - loss: 0.0484 - val_loss: 0.0668\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history=autoencoder.fit(X_train, Y_train,\n",
    "                epochs=450,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, Y_test))#,class_weight=weights) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEMCAYAAAD9OXA9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3xUVfr48c8zk94bHUJoUgREQKRaUARRUFS+P11FIyrqrot9xXXdXXd1dV11XdaCuCqWteAqCirFFpAiSlcpSi8hIYQUSJ/M+f1xJmEICUlgkkl53q9XXjP33nPvPfcyzDOnXjHGoJRSStUVh78zoJRSqmnTQKOUUqpOaaBRSilVpzTQKKWUqlMaaJRSStWpAH9noCFKSEgwSUlJ/s6GUko1KqtXrz5ojGlRcb0GmkokJSWxatUqf2dDKaUaFRHZVdl6rTpTSilVpzTQKKWUqlMaaJRSStUpDTRKKaXqlAYapZRSdUoDjVJKqTpVr4FGRO4SkTUi8q2IzBaR2BOkjReR9z1p14jI1ArbN4tISoW/XBGZ4JWmn4gsFZElIvKdiJxfl9enlFLqePU2jkZEJgJ3Av2MMTkiMh2YBVxWxS5vAFuMMRNFJAbYICJ7jDFzPNu3GmMu9Tp+NLAJWOBZjgTmA7caY+aKyFnAFyJyujFmb11c4xcb0/n5wGF+fV7Xuji8Uko1SvVZorkHmGWMyfEsTwfGi0iXiglFpDswFvgXgDEmGxt47ilL4x1kPK4B5hhjCjzLvwIKjDFzPem/B34AbvXZFVWw+OcMXl6yva4Or5RSjVK9BBoRCQQGAuvL1hljtgL5wNBKdhkK5BhjvEeZrgcGiYizitNMBl6pcIwNFdKsr+J8PuF0CC63PkhOKaW81VeJpgW2mi6rwvosoHUl6dtUkTYIiKuYWER6AwHGmDU1OEZl50NEpojIKhFZlZGRUdV1nFCAQyjVQKOUUsdoKr3ObuLY0kytGWNmGmMGGmMGtmhx3JxwNeJ0aolGKaUqqq/OAAcBF1Cxl1kskFZJ+rQq0hZToZTiqZa7Euhbw2NUdj6f0BKNUkodr15KNMaYYmA1XsHA0wkgDFhRyS7LgWgRSfRa1xf43hjjqpB2PLDE02Gg4jEqBp++VZzPJ5wOB6VugzEabJRSqkx9Vp09AySLSJRn+bfAXGPMVhHpJSIrRKQngDFmM7Zr8lQo77o8CXi6kuNOBv5Tyfq3gTARudRzjAHYQPOSD6/pGAEOAdBSjVJKeam3cTTGmNki0hZIEZFiYA+Q7NkcDfQEorx2mQTMEJEVQDDwjNcYGgA8x+sCLK7kfLkiMgZ4TkR+B4QAlxtj9vj2yo5ylgUaY/RBP0op5VGv34fGmGeBZytZvwKIqbAuE5hYzfFSgR4n2L4OGH5SmT0JWqJRSqnjNZVeZw1CWYlGe54ppdRRGmh8qLxEU6qBRimlymig8SGn095OLdEopdRRGmh8SNtolFLqeBpofOhoG43bzzlRSqmGQwOND3XZ+xF/C/iPlmiUUsqLBhofis3ZyBjnd9pGo5RSXjTQ+JA4AgigVEs0SinlRQONLzkCCMCNS7s3K6VUOQ00vuQMwKklGqWUOoYGGh8Sp606015nSil1lAYaHxJHAE4xlJaW+jsrSinVYGig8SWnnaO0tLTiI3OUUqr50kDjQw5HIABulwYapZQqo4HGl8pLNMV+zohSSjUcGmh8yOGwgcbtKvFzTpRSquHQQONDEqBVZ0opVZEGGh8ST9WZu1RLNEopVUYDjQ85ygONlmiUUqqMBhofcjg9VWcaaJRSDZHxz6wlAX45axOlJRqlVKWMgdISCAiqWdr966FFdygthuAoEPusK35eCId2QPcxsPzfUFIIQ38LLXtAqQsKsiA8AQ6nQWE27N8Axg1FuRDREr74M1z7PziwCbanQKdzYNdyEAe4CqD9IOgzsWb5rAUNND5U1kZjtHuzUk1TYQ44AuyXtzghKKz6ffIPwX8n2i//wbfBqtcgJApa94XcVEj/CTqfd/SLf+NH4CqEiFZwJB36Xw+j/wZfPQYrX7THXPCAzYcjENa9BdEdbIA6kgbhLeDw/qrz8+YEKMiG4sOw6hWvDQKrZ9lrOn3CSd+iymig8SGnVp0p1TgYc7SUAOB2Q+paaD/AbjMGinIgNNZu/+F/NlAsegha9YHSIjj4M7Q9E3pfZV83fgxZO+yXf+fzYOcSyNkH2bsh/6A9zqI/HD1n6tqj79e/bV83vGuPFdEKfl5g1615w/4BnH27Lels+wqG3w3OQHhvkj1vTCIkjYDUNXDmddBxOLTsCWk/2GvdtwZik2Dbl7ZUdONnUJwH0e3t8U6fAPtWQdI5Pr/dYvxUZ9eQDRw40KxatarW++Wun0vUnEl8MvgdLh0ztg5yppQ6Kdl7YMt8WzrIy4DXLoYjB8DhhMAw+4W88xu46lVIXQfLpx/d1xlkq7Cq4wzyVEEVHr/tjF9B7ythRwr0T4bQGMjeZQNZ0RF4aQRc+iwkDYfYTnbwd/YecJfAtq9t2u6XQOLZlZ+7pMAGOKd/yw4istoYM7Diei3R+FBZicZoiUap+vXdy7BpHpz/kC0p9L7CVm+Ft4AdS2DeVFuyWPYsFB22bRYAXS+BnN02yAD8b/Lxx+5wti3hjHsW8jPh68eg+1gYeJM99pbP7LEvecqWGLanQFCkrYKKbm/PFxYPAcHQ7cKjxw1POPr+dzts0PEuZcV0sK9xnau//sDQ2tyteqeBxoccAWVtNBpolKoTeZmQtsEGjO6XQFQbG0w+u89u37HYvi54wL46AsDtguhEGPkwLHnKNnoPnWqrmgYk2+3fv2K/5PeshMPpMGEGRLW1pZ/o9l4Z6AY3zPNavPDY4AG22sxbcGT11xUWV/N70AhpoPGh8jYatwYapcrlHTz213sZt9t+kUe0PPpLvqQQDm2DFj1sNdTSf4Kr6Oiv+0/vPVo1tT3l2ONd8EdY86ZtaE8aYQPJruXQcRgMuMGWKLqPhbVvwvm/P1oKcAbC0Dvs+yG/OfaYxwQZdbI00PhQWYkGnRlAKWv167ba6pavoN0AcJfaAFKYA0ufgWX/gojWthSQl2EbqgE6DLalkV1Lqz52RGsY9YgNLr3Gw9m3woh7j01z9q3HLrfqBWMe9+UVqhrQQONDZY8JMG4NNKoZM8b2fIpsC1/8ya77+A44bTSsetW2XxxOtW0oYLvkbnj32GPs+daWSIbdCZs+gUG32LaS7Sm29NPtIojvZsd7nHF1vV6eqj0NND7k8EyqibbRqKYm1zMu40iaHc9xYKOtiup0DuxeaUsUh/fbz/4Ps227B9ieWF1HwdbP7T5gSyKhcbbL77Uf2P0i29g2kfyDdlzJjm/gsuds28WFjxytWmvXv/6vXZ0yDTS+5HlMgHHro5xVI7N9se3u23eiXc7eAwumQc/xUHzEto2IA0yFz/ah7fZ18SbPdrf9f9D2TDu6fcJLtgdYSYFtaM/ebbsYg11XWW+pTufA4NuPLnv3xFKNkgYaX/IEGrQzgGosPv+jbaxf91+7nLEZuoyEj38NWTth8yd2fefzbO+pTfNg3HTocYn9nGdutVVaJQU23cLfw1k32UBTmGsb5sEGlM7nHXvuBt4lV/mOBhpfcmj3ZtUAGWNLGntXwdYvoOc4aHW6nepk2b+OphMHfPOU/QuOgl/Nhp8+gqBwuOhRW1WW/iO06n20lBHZ2r56elxy2XNHj1cWZFSzp4HGlxxO+6olGtUQuN2wfx28OsZOmVJmyZMQ39WWRsCOMelyHox9CnL32ZHxHQbZrr2njT72mK371Fv2VdNRr4FGRO4CrgeKgd3ArcaYrCrSxgMzgA5AEDDLGDO9QpphwJ+BECAO2GKMucKzLQlIAXZ67bLOGHOXr67nOOVtNNrrTNWj/EOw93tbqigptIMYFz18dLR7md5X2ob4b5+3QabLSFudNeSOoz+S4jrXbCS6UrVQb4FGRCYCdwL9jDE5IjIdmAVcVsUub2ADx0QRiQE2iMgeY8wcz/H6Ai8CY4wxqSISBnxc4RizjDF/roPLqZwn0IhWnam6cuQAhCWAw2GrxOZNPTrhYpmQaDtOpUync+DM64829I98CPattoMataFd1YP6LNHcg/3iL/sfMB34RUS6GGO2eScUke7AWODXAMaYbBF5w3OMOZ5kfwReNMaketLkA6Pq/jJOoGyuM606U75WmAsb3rNTrbTs5XlOSaSd1ytxiG1Yz8+0wSdtA1w+w47GTxwCASHHTrYYFG6Dj1L1pF4CjYgEAgOBv5etM8ZsFZF8YCiwrcIuQ4EcY8wur3XrgftFxAm4gYuAr0VkHrbabBfwYIV9honI50AYsBl4uCww1YnyXmfavVmdgvSNdi6vFt0hpqNtL/ngZts9GOx4lC4XQM5e+3rt/2wJB2y7zMEtdjZipRqI+irRtPCcq2J7TBbQupL0bapIG4QNKgCR2BLOucaYvSLyZ2CxiPQwxhQChcBabMmnGHgS+EZETvdsP4aITAGmACQmJtb6AgGvzgDaRqNqoTjfDlo8sNFOEf/KRVCSd2wacUK7gXYMSv/rq67ycjg0yKgGp7H2Ogv2vL5pjNnref8E8HvgEuADY0wa8LuyHUTkYeC3wDjg/YoHNMbMBGaCfR7NSeVKSzSqpvatgZw9dk6vmece+0TEiFYQ18l2JT7vQTs7cYdB2uNLNVr1FWgOAi4gtsL6WCCtkvRpVaQtxpZsQjzryqvBjDGFIpIJdKwsA8aYAhE5ACTVNvM1pgM2VXVWvmQfZPXzfLucOPT4x+6O/ht0GwUZP0OHs+o/j0r5WL0EGmNMsYisBvoCHwGISBds28mKSnZZDkSLSKIxZrdnXV/ge2OMCzgiIpvwqnYTkQBsMNrjWZ4KfFzWZuPZngDsq4NLtMp6nWmgaX7KSrFl1adlio7YiSW3fQ0l+ccHld3L4dxpdg6xc35nq8Si2tptGmRUE1GfVWfPAE+IyLPGmFxsNdZcT6eAXsArwGRjzCZjzGYRmQ9MBe4TkWhgEnC31/GeA+4UkX95erLdBGQAnp+K9AdaAmUP6b4TyAE+rbMrlLIGWQ00zc7r4+xULpc+Y5+o+PVjcGinDRxFudD+LHCFQ+u+0GOsnbZl3l12qpbzpmk3Y9Wk1VugMcbMFpG2QIqIFGNLHsmezdFAT8B7zopJwAwRWYFtk3mmbAyN53gviEgcsFREsoE8YJQx5ognyUxgmogs8yyXbfcaYOBjIrgIQCpOPKiarlIXrH0Ddnk+ZrMusa9BkVB82A6IHHFv5d2Jb1pYX7lUyq/qtTOAMeZZ4NlK1q8AYiqsywQmVnO8R4FHq9i2HBh/0pk9SaXi1Kqz5uSTu+wTG8FONhneAgqz7ZMcHQF2zIqWVlQz11h7nTVYbpxaomnKUp6wMxy7S2HTXLsuJNpWiZ153fFtNEopDTS+5tYSTdNgjC2JrHvHPukxoZud6iXF6zHAsUkQFAE3LbIlF6VUpTTQ+JhbtETTqBVkw+xJUJBlp3rZ8J5d7wg42snjtqV2WQdGKlUjGmh8rFQCcBqdGaBRMcYGkaxdMOdW2LfKrk/7wb5e+Gfboyy+CxTn6cBJpWpJA42PlUoADp29ueEzxj4NsigXMrfBbq/hXOfcD3kZEN0BOg6DjkP8l0+lmgANND7mlgCcaImmQcpNhQ+nQPuBsOF9yPXMXiQO6DMRjqTb0ku7Af7MpVJNjgYaH3M7AgkwWqJpcNyl8OVf7MPAdn5jSysXPmIHUka1tXOLKaXqhAYaHyuVQBwaaBoGY2yAWfoM/PQRHPgJBv/azn4c2wkCQ6o/hlLqlGmg8TEt0TQQBVnw+nhI/wlMKbToCVe8bKvIdAClUvVKA42PGUcATg00/uN2w+cP29H6hTnQ92roOQ56XurvnCnVbGmg8TG3BBJIgb+z0Xx9/zKseM6+H/9vW02mlPIrDTQ+ZpyBBFCK221wOLSKps653Xaq/UV/gNS1dl2XkTBxlp0aRinldxpofMxIAIG4cLkNQRpo6lbOXvjfZNizEhyBdl2PS+Gq1yAgyL95U0qV00DjY25nkCfQuAnC4e/sNE25qXZyy3X/tSP6h90FQ6faCS1DorWxX6kGRgONjxmHrTorKTX+zkrTdOSAHXS58xvodRkMvwfa9vN3rpRSJ6CBxtecQQSJC1ep2985aXrWvAnzpoJxw6XPwsAb/Z0jpVQNaKDxNcfRNhrlI7tXwtw74ODP0HE4jH0SWp3u71wppWpIA42PGWcggbgo0EBz6koKYdZY2LcaYjrCuQ/AoCkQnuDvnCmlakEDja85ggigVKvOTtWOJbBsug0yXUbaqrLYjv7OlVLqJGig8bWAIIJwaWeAU/H5H2HZv8AZDGP+DoNv83eOlFKnQAONj4mn6szl1hJNrRQdgfkP2N5k2bug/w0w5gkICvN3zpRSp0gDja85A3GKwVWi853Vyhd/gnVvQdIIOPM6GH43OAP9nSullA9ooPExcQYD4Cop8nNOGgF3KfyyCNa/Axs/hrNvh4uf8HeulFI+poHG15z2lrpdxX7OSCPwwU3w0xwIioDzfg/n3OfvHCml6oAGGh8TzxxbpSUaaKpUUgBzbrWlmGF3wvl/0LnJVI2UlJSwd+9eCgsL/Z2VZikkJIT27dsTGFi7am0NND7mCLBVZ6VaoqncwV/g/Rsh/QcYcocGGVUre/fuJTIykqSkJETntKtXxhgyMzPZu3cvnTrV7tHnOuujjzkD7Zemq1jbaI6Tug7evRaydtqnXY5+TIOMqpXCwkLi4+M1yPiBiBAfH39SpUkt0fhYgCfQlJRo0b6cMbB6Fnx2PwSEwBUzocdYf+dKNVIaZPznZO+9BhofCwi0VWclxVp1BkDeQdses/UL6HIBXPUKhMb6O1dKqXqkgcbHAoO0e3O5A5vgtbFQfAQufhLOutk+M0Yp1axoG42PBXpKNM2+jWbDbHh5JDgC4NYlcPatGmRUs/HEE0+QlJREcnKyv7PSIJx0iUZEooAYAGPMbp/lqJHTEg3w80KYcxt0GATjn4OErv7OkVL1atq0aRQWFrJz505/Z6VBOGGJRkQKRGS7iCRXsnkC8DqwoS4y1liVBZpmO45m90qYfQO07gPXvq9BRilVbYnmW2PM+QAi8seylcaYvxhjXgdeF5EVdZnBxkYCQwEwJQV+zokfbJoHH98BUW3h2v9BcKS/c6SauEfm/cTG1Nx6OVevtlH8adzJPXAvNzeXe++9l02bNmGMoVevXjz99NNERUVhjOH+++/nm2++ITIyksDAQP70pz8xePBgtm3bxm233UZJSUn5fk899RTh4eE+vrq6VV0bjfdc97uBq4GdJ0hzQiJyl4isEZFvRWS2iFTZ/UhE4kXkfU/aNSIytZI0w0TkcxH5RkR+EpEPK2y/QES+E5ElIrJURPrWNK8nLTgKAGfx4To/VYNhDCx8CN67DqLbw6QPIaKFv3OlVIORnJyMy+Vi6dKlLFu2jKKiIm680T6KfOHChXz66aesWLGCL774gptvvpkFCxYA8NBDDzFy5EhSUlJISUlh3759ZGRk+PNSTkqN22iMMbNE5AZjzBsncyIRmQjcCfQzxuSIyHRgFnBZFbu8AWwxxkwUkRhgg4jsMcbM8RyvL/AiMMYYkyoiYcDHXufrCMwBzjPGrBGRK4D5InKaMSbvZK6hRkI8gaakfn5l+Z3bDe9fb0szZ91sp/bXWZdVPTnZEkZ9Sk9PZ86cOaxYcbTy5/bbb2fo0KGkp6cTGxvL3r17ee+995gwYQITJkzgkksuASA2Npb58+czevRo+vfvz+zZswkKanyDnKsr0cSKyPkiMlJERgIx3suedVE1PNc9wCxjTI5neTowXkS6VEwoIt2BscC/AIwx2djAc49Xsj8CLxpjUj1p8o0xo7y23wasNsas8Wz/EHBjS2V1JyQagIDiI3V6mgahMMdOjLlpHpz/EFz8Dw0ySlWwa9cuAFq2bFm+rlWrVgDs3r2bs88+mzlz5vDuu+/Srl07kpOTOXjwIAD//Oc/GT9+PMnJyXTt2pXnn3++/i/AB6oLNGcAXwCfe/76Vlj+HOhZ3UlEJBAYCKwvW2eM2QrkA0Mr2WUokGOM2eW1bj0wSEScYoenXgQ4RGSeiCwTkbc9pRjvY6znWBuqOJ/vBIRQQgCBTb1EYwx89Gv46UMYcCOccz84tLe8UhUlJiYCtmRTpux9YmIiOTk5DB06lI8//phffvmF7Oxsrr/+egCysrK477772LBhA2+//TaPPfYYb731Vv1fxCmqyTeDVPNXEy2w1XRZFdZnAa0rSd+mirRBQByQAERiSzi3G2OGAT8Di0UkpJpjVHY+RGSKiKwSkVWnVAcqQp6EE1TahEs0xfkwbyps/gRGPw7jngWdFkSpSrVu3ZrLLruMGTNmlK978cUXufzyy2nVqhVz5szhhRdeACAuLo5+/frhctkHJyYnJ5OamgrAmWeeSVxcXPm2xqS6Npr1wF0n2C6AP8pywZ7XN40xez3vnwB+D1wCfFDbAxpjZgIzAQYOHFjjDg6VKXCEE+xqooHGVQyzJ8HWL+2Dygbf7u8cKdXgPPHEE8yaNYvCwkLuvfdeZs2axb333suwYcMA6NGjB7NmzQJgyJAhPPDAA8yfP5/CwkKCgoLKg9J1113H1VdfTWBgIIcOHWLs2LHlpZ3GpLpA86QxZvGJEojI4zU4z0HABVTsZRYLpFWSPq2KtMXYUklZqSW1bKMxplBEMoGy6rOqjlHZ+XyqwBFBSFMs0eQdhPeTYec3MG46DLjB3zlSqkGaNm0a06ZNO2bdK6+8Umna7t2789FHH1W6bdKkSUyaNMnn+atvJ6w6M8a8U9l6EYkoq6IyxlRbYWiMKQZWY9t4yo7RBQgDKhuHsxyIFpFEr3V9ge+NMS5jzBFgE17VYCISgA0ke7yOUbE7c58qzudThc5wQt1NLNC4S+HDKbD3ezvaX4OMUqqGqpsZ4AIR+ZuIXONZThCRFCAHOCwiH4pITUflPQMke6auAfgtMNcYs1VEeonIChHpCWCM2QzMB6Z6zhsNTAKe9jrec8C1nm0ANwEZnv0AZgADRKSf5xiXA07g3Rrm96QVOSMIddddD+p6dyTDPkdm25dw8d+hf+P/haWUqj/VVZ3dDiQBCz3L04FzPO9zgXHYdpEHqzuRMWa2iLQFUkSkGFvySPZsjsb2XvPuKj0JmOGZeSAYeKZsDI3neC+ISBywVESygTxglKe0gzFmp2fszEwRKcQG1YvLttel4sBIwvLy6/o09aMgG96aYJ+MedGjMCDZ3zlSSjUy1QWabsC5xphsT8nlSuxMAJ8B44EewGxqEGgAjDHPAs9Wsn4Fngk6vdZlAhOrOd6jwKMn2P4lMKgmefOlooAoosm1gxkbc5ff4nx452o4sBl+9S50vdDfOVJKNULVfQse9AyWBBgGlI3Ge8lYm4BDdZa7RionrCPBlED2ruoTN1SFObZ32e5v7RMxNcgopU5SdYEm2Ov9pZ5XF/B13WSnaciL6Q6AK+0nP+fkJOWmwn8uhG1fw7h/Qe8r/J0jpVQjVm29jojc4+kMcAO22uzrsrnCRKQHx3chbvZMSztZQmHqj37OyUnI2gWvXQy5++GGudq7TCl1yqpro/krMA/bW0uwgeYpABG5E3gAWFCXGWyMYqJj2eVuSdze1f7OSu0c2AxvToCSPLj+Y2g/wN85Uko1AScMNMaYhSIyFNsJIATbHbms2syBnRVgYVX7N1dx4UEscfflV3uXgqsIAoKr38nfdq+Ed/4fOIMg+VP74DKllPKB6sbRzDLGrDLGPGiMudsryGCM+acx5jHgjjrPZSMTHxHMl+4zcbryYXuKv7NzYm43pDwBr42BkBiYvFCDjFJ+8sQTT5CUlERycnK1ac877zxCQkJISUmp83ydquqqzkaLyKvVpLnIV5lpKhIiglju7k1BYCyha9+E00b7O0uVK8iyMzBv+Qz6/j87GDNUm9yU8pdp06ZRWFjIzp07q02bkpJCUlJSnefJF6oLNK2wnQCqUtZuo7xEhQRS6gjih4SxDNryHhxOh8hW/s7WsTZ/aoNM0WG4+EkYNEVnYFZK1YmaPGGzgOOn2/eW4KO8NBkOhxAXHsTiiLEM2v9fWPMGnHu/v7Nlpf0Ai5+ETXOh7Zl2csw2df+Ea6XqxPxp9jNdH1r3gYufqDZZQUEBw4cPZ82aNYwYMYLPPvuM3bt3c80115Cbm8vrr7/O3/72N0pLSykuLmbIkCE8/vjjiA9+6H333XdMmzat/Ni33357+WzP27Zt47bbbqOkpARjDL169eKpp54iPDycN954g+eee46IiAjcbjeTJ0/26SzR1QWaq7HT0OQCzxtjFlVMICI6pqYS7WJCWZsfAd1GwzdP2eozf36hH06HFc/ByhkQGAZDp9qnYgaGVL+vUqrGQkNDWbp0Ke3ateP3v/89ERER9OrVi3HjxjFq1ChKSkp47LHHGDDA9uq8/vrreeutt055lubU1FQuvPBC5s2bx7nnnktaWhp9+/YlNjaWcePG8dBDDzFy5EgefPBBjDFcdtllZGRkYIxh8uTJ7NmzhzZt2rBv3z5uuumm+gs0xpjZwGwR6QvcISJ/xz5S+TWvGQN0NF8lOiWEs3J7Jvz2OXjpXHjvOrh1cf23gWTvgRXP21KVqxC6XQSXvwBhcfWbD6XqQg1KGP4QGhrKddddx8yZMxkzZgylpaUsX76cRx99lLS0NB5++GF++ukngoKC2LlzJ5GRkaccaN58803atm3LueeeC9gHrk2YMIEXXniBcePGERsby/z58xk9ejT9+/dn9uzZBAUFUVRURFRUFC+99BK/+c1vaNeuHR9++KEvbkO5Gk3EZYzZYIyZApyPbZdZJyIvi0hPY8yJqtWaraT4cFJzCikMjof/e92Otn/7ajsTcl0zBrbMhw9ugX+dAd+/DL3Gw2++s3OWaZBRqs7dcsstzJs3j7S0ND799FPGjh0L2GfMZGZmsnjxYlJSUkhOTiYv79Rne9+1axctW7Y8Zl2rVq3YvXs3AP/85z8ZP348ycnJdO3aleeft2Nt3iUAACAASURBVM+sDA0NZcWKFaSmpnL66adz0UUXsXbt2lPOj7caz/goIg7gQuxkmonAZGy1mqpEUkIYALsy86HDIDtf2P518OJQ+O5l+3wXXyopgK1fwILfw4wRdjLMzZ/C2bfC1HUwYQYkdPXtOZVSVerTpw8DBw7k1Vdf5fXXXy/vsrx8+XIuvvhiAgPt1JHFxcU+OV9iYiLp6enHrEtPTycx0T7WKysri/vuu48NGzbw9ttv89hjj/HWW29RUlJCfHw8M2fOZO/evQwfPpzRo0eTn++7GehrMgVNCxH5A7ALeA8Y4dm0G/jKZzlpYrq0iABgc1quXdH7CrhpESR0g8/ugyc7w3uTIOXvsO4d2LkMDm2vPgC53XbK/l3LYdl0eOUi+/f3JHjrSvj+PxASDRf8ER7YCWMeh5gOdXqtSqnKTZkyheeee47Q0FASEmy/qR49erBkyRIAioqKWLTouKbvkzJp0iT27dvHV1/Zr+W0tDTmzJnDbbfdBkBycjKpqfahxGeeeSZxcXG4XC727dvH5MmTMcYQFBTE8OHDcblcPumcUEaMqbp3soi8hZ0VIIijXZkXAS8An5gT7dyIDRw40KxateqUjlHqNvT/6+eM6tWKpyaecXSDMbD5E/h5AWxfAjm7j90xOAoQ29U4MNS+d7s8f6W2naW06Gj6+K52n8TB0OUC6DgUgsJOKe9KNVSbNm2iZ8+e/s5GjeXn59O2bVs+/PBDRo4cCcDatWu5+eabERE6d+6My+Vi+fLl3HrrrYSGhjJjxgwKCwu59tprefrpp6s89nnnnce3335Ljx49+Mc//sGoUaP49ttvmTZtGm63m+LiYqZMmcLkyZMB24bz8ssvExgYyKFDhxgxYgTPPPMMRUVF3Hffffz44484nU4OHz7Mww8/zOWXX17peU/0byAiq40xA49bX02gcWODSzbwKvCiMWZ7hTSvGGNuqvIgjZAvAg3AHW+vYeWOQ3z74AU4HVX8OigphJy99pECOXsgdZ2dssYYKPEUXR0Bnj8nOAOhRQ8Ibwmte0NU21POp1KNRWMLNE3RyQSamoyjyQM+x46X+UOF4pQADXTYu/+N6d2aTzbsZ8W2TIZ3q2K4UWCIbTspaz/ReSyVUk1MdYFmPXDXCbYL0M932WlaLuzZiqiQAD5cs7fqQKOUUlW4+uqrSUtLO279mDFjmDZtmh9ydHKqCzSPG2MWnyiBiDzuw/w0KSGBTkb1as3nG9MoKXUT6GzEj3VWStW7d999199Z8IkTfvN5BmyeUE3SNGejerUkt9DF9zv0iddK+UIT7YPUKJzsvdef2HXs3NNaEhkcwOxVe/ydFaUaPafTSUlJib+z0WyVlJQQEFCTpv1jaaCpY6FBTq4c0J55G/bz8bp9/s6OUo1aTEwM6enpuN1uf2el2XG73aSnpxMdHV3rfWsfmlSt3XPRafyUmsO0D34gLjyIEd1a+DtLSjVKCQkJ7N27ly1btvg7K81SeHh4+cDT2jjhOJrmylfjaLztzsxn/PNLyc4v4cVr+zOmd2ufjrxVSil/q2ocjVad1ZPE+DAW33c+HeJCuf2/a7hx1vfszfLdXEJKKdVQaaCpR9FhgXz062E8MKYH3+04xEX/XMIrS3dQWOLjCTaVUqoB0aqzStRF1VlFe7PyefijH/l6i31swNAu8Yw/oy1XDmiv422UUo3SSc111lzVR6AB2yd94U9ppGzJ4ItN6Rw8Ukx4kJP+HWN5YEwPererfe8OpZTyFw00tVBfgcabMYbFP2fw1eYDzP8xjcwjRUSHBtK7XTR92kUzpEs8w7smaAcCpVSDpYGmFvwRaLwdPFLEf77Zwd6sfL7dfojs/GJcbsOIbgkEBzhIHtqJIV3iq54RWiml/OBUZm9W9SwhIphpF/coXy5ylTIjZTsvpGylyOXmi00H6JwQzs0jOtOzTST9OsRoSUcp1WBpiaYS/i7RVKWwpJTs/BLmrU/lzW93sfuQ7R59zaBEBneO44z2MSQlhPs5l0qp5kqrzmqhoQYab4UlpWxJO8zsVXv470r7lM4Ah3DziM4M7hzHuae10FKOUqpeaaCphcYQaMoYY1izO4tDeSXMXrWHzzemA/DgxT04v0dLTmsV6eccKqWaiwYRaETkLuB6oBjYDdxqjMmqIm08MAPoAAQBs4wx0722J2MfypbttdssY8wsz/YkIAXY6bV9nTHmRA9yAxpXoKkoJ7+Ea17+lo37cwGYOrIrt5/XldAgp59zppRq6vzeGUBEJgJ3Av2MMTkiMh2YBVxWxS5vAFuMMRNFJAbYICJ7jDFzvNLcZYxJOcFpZxlj/nzquW88osMC+fDXQ/kpNYe/fLKJ6V9tZenWgyQP60T/xBjax4b5O4tKqWamPoeg34P94s/xLE8HxotIl4oJRaQ7MBb4F4AxJhsbeO6pp7w2aiGBTgZ0jGP2rYN5aGxP1uzOZuo7axn376Us33oQt1urS5VS9adeAo2IBAIDgfVl64wxW4F8YGgluwwFcowxu7zWrQcGiYh3HdAUEUkRkW9E5C8iElzhOMNE5HMRWSYir4hIW99cUeMQHODklnM688HtQ/ntyK4EBzj51X9Wct0rKyko1vnVlFL1o75KNC2w1XQV22OygNaVpG9TRdogIM6znAYsAkZiSz/nAK96pS8E1gLjgBGe/b8RkZCTvopGakDHWO69qDufTB3O3ReexvJtmfx9wWZ9JK5Sql402tkbjTELjDGzjDFuY8xh4K/Ar0SkhWd7mjHmd8aYQmOMG3gYaI8NPMcRkSkiskpEVmVkZNTbddSnhIhg7rywG9cNTmTW8p389p21HCly+TtbSqkmrr4CzUHABcRWWB+LLZlUlFZF2mKOL+mU2el5TapsozGmADhwgu0zjTEDjTEDW7Ro2k/AfGR8b6Ze0I1PNuxn+N+/4vON6ZSU6qNxlVJ1o14CjTGmGFgN9C1b5+kEEAasqGSX5UC0iCR6resLfG+McXn2f7rCPm08r/s826eKSEev8wUACWXbmzOnQ7j7wm68edMgokICueWNVVzw9GIt3Sil6kR9Vp09AySLSJRn+bfAXGPMVhHpJSIrRKQngDFmMzAfmAogItHAJMA7uFwhIhd6tgdge6QtMMakerb3B27xSn8nkAN8WidX18iICCO6tWDR3efwzP+dwe5D+fT+00KWbT3o76wppZqYegs0xpjZ2C7NKSLyLdAOSPZsjgZ6AlFeu0wCOorICuBr4JkKY2j+CPxJRFKwJaBs4Dqv7TOBvp4eZ8uA0cAor+7VCtsV+or+7UkemgTAvbPXk1NQ4t9MKaWaFJ2CphKNeWaAU7F+TzZXvLicNtEhtIkO4eYRnbmoVyudM00pVSNVzQzQaHudKd87o0MMT1zRh/iIYHZl5nPrm6t5ddlOf2dLKdXI6fNo1DEmDuzAxIEdKCl1c9Prq/jrJxtZvyebv1/ZV+dLU0qdFC3RqEoFOh08ellvuraMYO76VHr+cQE3v75KB3kqpWpNA42qUmJ8GJ/8djijT29Fvw4xfLEpnQufWcyKbZn+zppSqhHRQKNOKCTQyUuTBjL71iGc370FB48Uc83L3/Lghz+QW6i905RS1dM2GlUjQQEOXrtxEAXFpTzz+RZeWbqDrzan8+jlfRjVq5W/s6eUasC0RKNqJTTIyUOX9GLOr4cRGxbELW+s4v7312vbjVKqSjqOphLNdRxNbRW73Dy1aAszl2wnMjiAgUmx9G4XzZRzOhMZEujv7Cml6pnfn7Cpmp6gAAcPjOlBWk4hX20+wNdbMvh6SwYLf0pj0pAkruzfjrAg/Ygp1dxpiaYSWqKpPVepm5yCEtbszuY3/11DcambMae35uI+rRnZo6WWcJRqBqoq0WigqYQGmlOzaX8uTy3cwpebDwDQMjKYG4Ym8atBicSGB/k5d0qpuqKBphY00Jw6Ywwrdxzi843pfPbDfvbnFBIa6OR3Y7rTOiqE0ae3xuHQOdSUako00NSCBhrfW7XzEJNe+Y6CklIALunbhvsv6s6h/GLax4TSMqrZPWFbqSZHOwMovxqYFMc7UwaTllPImt1ZzFyynU837Adsp4J7Rp1Gj9aRZOUXM+HM9n7OrVLKlzTQqHrTr0MMdIAxvVszvGsCry3bwbaMPErdhifmby5P1ykhwqZVSjUJWnVWCa06q18FxaVMemUlq3Zlla/76+W9yS9ycfWgRKJDtceaUo2BttHUggaa+ncgt5An5m+mTUwIz3+97ZhtD43tSe920USHBtKjdaR2IlCqgdJAUwsaaPwrPbeQJxds4YM1e4/b9pvzu3D/6B5+yJVSqjoaaGpBA03DUFBcyo6DeWzcn0ugU/jPNzv4YV8OV5/Vgd+c35WWUcH8uC+HAR3j/J1VpRQaaGpFA03DVOQq5ZlFPzPzm+04RXC5j352f3V2IjcMSaJ760g/5lCp5q2qQKOzN6tGIzjAyYNje/LVvecd1yvt7ZW7uWT6N7yQshW3W388KdWQaImmElqiafhK3Ya1u7MIDw7AGIiPCOIvn2zk0w37CQpw0LddNP07xvK70d3ZmnGEhIhgEiKC/Z1tpZo0rTqrBQ00jZMxho/W7eOrzRl8sTG9fBYCgLOSYnk1+Syd3FOpOqSBphY00DR+xhimf7mVf3/1S3lbjtMhtI0JIcDh4A+X9OSc01oQ4BBEtLu0Ur6ggaYWNNA0HYUlpbz3/R7+NPcnYsICyc4vOWb7kM7xvD55ED+nH6ZTQjjhwTpZhlInSwNNLWigaVpK3Yb5P+5nVK9W5BSUEBMaRL+/LCK/2FatiYAxEBkcwNQLunHVgPb6OAOlToIGmlrQQNP0rd+Tzdz1qZzRIYap76wFIDIkgMOFLlpGBhMeHMDdo05j/Blt/ZxTpRoPnb1ZKS9ndIjhDE8X6RKXm5BAJxf0bMncdan87oMNcLiIqe+sZe66VKJCAxjVsxUX92nj51wr1ThpiaYSWqJp3nZl5rEt4wizlu8iPaeQzLwiDh4ppmN8GNcPSeKm4Z38nUWlGiStOqsFDTTKW8bhIs5/KoUjRS4AruzfnkJXKfuzC8g4UkTb6FBG9mjJlHM6aw821axp1ZlSJ6lFZDBf3XcukcGBPPbZRmav2ovbbcq7Te85VMDKHYdwOoQzE2PZnJaL2224ckB7woLsf7HcwhJKXG7iddCoaoa0RFMJLdGoE8nJL6HIVcrhIhdrdmXhEOHJhZtJzy06Jl18eBDndm9B77bRvLh4G8YY5t4xnLYxoX7KuVJ1S6vOakEDjaqt/GIXP6cfYV9WAW1iQih1G55Z9DMrtmcCEOR0UFzq5pzTWvD6jWchIqTnFhITFkhwgNPPuVfKNzTQ1IIGGuUrf/tsE5lHivnHVX15fcVOHpm3kdPbRrE7M5/DRS7O7hTHmN6taR8bxuHCEgpL3Fw1oD1BATrfrWp8tI1GKT/4/die5e9vGJLEim2ZpGzJ4KxOsWQcLmLljkOs3HHomH1+Tj8MQJHLTUGxi81ph/nvzWdr+45qtOo10IjIXcD1QDGwG7jVGJNVRdp4YAbQAQgCZhljpnttTwbuArK9dptljJnlleYC4HGgEPtIhF8bYzb48JKUqjGHQ3hp0gDcxs67BvD9zkNsPXCEmNBASo1h4U/pzFq+87h9H/t0E3+5vDcRXlPkZBwuwm0MraJC6usSlDop9RZoRGQicCfQzxiTIyLTgVnAZVXs8gawxRgzUURigA0isscYM8crzV3GmJQqztcRmAOcZ4xZIyJXAPNF5DRjTJ6PLkupWhERnF49oM9KiuOspKNPCB3ZoyXx4UG0iwmlS8twZi3fhavUzYdr9/Hh2n30bR9Nn3bRZOeXMP/H/QQ6HTx5VV8u7duWrQeO0LlFOAEO4f3Ve+mcEM7AJH36qPK/emujEZEVwAJjzCOe5a7AL0BXY8y2Cmm7A5uBJGPMLs+6R4FzjTEjPMvJwM4TBJrHgcHGmPO91u0B/myMeeVEedU2GtWQuN2GD9fuY/ehfBb8uJ+f048A0LlFONsz7G+m09tG8VNqLgBXDWjP/1bvBeDSvm24f3R3OsSG4fCUokpK3QQ6tQ1I+Z5fOwOISCCQD0w0xnzktT4PuM0Y82aF9DcC/zTGxHitmwi8BYQZY0o9geYioC3gBL4GHjPGFHnSLwbWGmPu8jrGp0CaMeamE+VXA41qqFylbjKOFNEyMgSnQ9iWcYTnv97Kh2v2nXC/+PAgnA7hxmGdmP7lLzw2oTc920TRpUUEQQEODT7KJ/zdGaCF51wV22OygNaVpG9TRdogIA7IANKARdgqtnBgHtAFuNbrGF/V8HyIyBRgCkBiYmJ116OUXwQ4HbSJPjoOp0uLCJ666gzOaB/DkC7xtIkO4dJ/L6WguJS5dwxn8ONfApBfXEpBSSl/X7AZgHtmrwegR+tI+nWI4eN1qdw4LIkAhxAc6GR41wT6to/WmQ6UTzTaXmfGmAVei4dF5K/AFyJylzEm4ySONxOYCbZE46NsKlXnHA7hhqFJ5ctf3XseecUuokIC+WzqCGLCAglwCnlFpcxZu4/s/GJWbj/EBT1b8p9vdrA5zfZyeyHlaA32PxZuAeC3I7syqFMcfdvHkJVXzKOfbmTqBd347Ic0bhjakdwCF3PW7uP+0d3LOzgoVVF9BZqDgAuIrbA+FlsyqSitirTFHF/SKbPT85rE0RJPTc+nVJPhdAhRnkdW92obdXRDJNwz6rRj0l7cuw3ZBcV0bhHB/uwCwoICuOu9teXtQP/+aisA7WNDCQty8nP6EZb8fJDiUjdz1u4tnw0hwCEcLixBROjdLprdmXlk5Zfw4NgehAQ4KTVGq+aasXoJNMaYYhFZDfQFPgIQkS5AGLCikl2WA9EikmiM2e1Z1xf43hjj8uz/tDHmXq99yuZw3+d1jEEVjtsH2xNNKQX0aR9d/r6dZ2qchXedQ1puIanZhbhK3WTlF/PQnB/Zl11An3bR/Jiaw3WDE/l0w/7yfZ/7emulx3/z210EOoUAh4MxvVuTml3AFf3b8X8DOxxXLXe4sIQ9hwqODY6qSajPXmf/BzyB7d6cKyLPAp2MMZeJSC/gFWCyMWaTJ/1nwEZjzH0iEg2sB+4u694sIjuAW4wxX4hIADAbCDXGXOzZnuTZ51xjzDoRuRx4HuhujDlyorxqZwCljrUvu4A9h/Lp2z6anQfz6dU2Clepmy83H2Bwp3g2peXSNjqUWct38uqyHcft3zE+jF2Z+eXLbaJDOCspju0Hj1BU4uaRy07nrnfXceBwEW9MHsSIbglsST/Ma0t38tClPctLaJX5Jf0wLSKDiQnTp6L6W4OYgqbCgM09wBRjTJaIDAHmA6ONMSs9acsGbLYHgjl+wOYkbON9KbZk9CNwvzEm0yvNSQ3Y1ECj1MkxxnDwSDGFJaW0iAwmwCEcKXIRHRrI3qwCcgtLmPLGavZlFwC2N1xmXvFxx+naMoJ9WQUUlJTSu10U53RrwepdWfTrEENCRDAT+rcjISKYguJSev5xAd1bRbLw7nPq+3JVBQ0i0DQWGmiUqlvFLjefbEjlgh6t+M/S7cxYvI2ZkwbSt300839M499f/UJ6bhE920SxLeMIxS73MfsHBzhIiAgmv9hFVn4JANcNTqRjXDiXntGGfyzcQm6Bi/4dY7jmrER+2JfDK0t3cP/o7nRrFaETmdYRDTS1oIFGqfpjjCG/uJRwr+l18opc7MrMp3vrSIpdbgyG7PwSZq/aQ3RoII/M21jtcYMDHBRVCFAAfdtH8+bks8k4UsRv31nL2Z3imDysE06nkFfk4rRWkQAs33aQH/flcOOwTuUdGYwx2uX7BDTQ1IIGGqUatiNFLoIDHHy9+QBnJsYSFRrAuH8vLe8td/2Qjjwy/nSWbj3IlrTDbNibw9z1qeX7d20ZQVZecXm1XURwAG5jMAYeuex00nMKefrznwFbUrr/oh7MXb+PWct38sK1AwgNdNI+NpSdmXm0iAwm8gRtSABFrlKy8kpoHd2056XTQFMLGmiUanxKSt3sysxn6S8ZTBqSdNy4nrnrUzHGEBzg4La31tA2OoRXks9i+bZM/v3VL7SOCikfUwQwqFMcbaJD+HhdKiLg/VXpdAi92kTxw74cAMb2ac1VA9rz1082cfVZHRjVqxVPLdpCVl4J15ydyJsrdvL9ziy+vu88OiWEH5d3V6mbgCbQ/VsDTS1ooFGqaft8Yzp920eXz3ztKnUjIlwy/RtGdEvgmkGJdIwPZ2dmHhOeXwZAZEggV/ZvR3RYEDMWbyPjcBGnt41iUKc43lyxq/zR3tU5v3sLerWNon9iLNsz8njss00A/OvqflzWrx1g57dzOISV2zO59a3VzP3NcBLjw+rgTviWBppa0ECjlDqRA7mFbE47zLCuCTgdwucb07nljVWM7dOaOy84jdHPLgHg+4cuZF92AflFLtJyC7ln9nraRIeQlltIxa/eAIdw1YD2dG4RzswlO+jeOoJlW20n2tPbRtG9dSRnd4pj4oAOOBxCVl4xuw7lEx8eRIe4MDam5tIpIZzQINvRIfNIEXHhQfXapqSBphY00CilauvLTen06xBDfEQw3+04RGp2AZef2e6YNHsO5dM+NpQil5t/f/ULoYFORp/emo37c3n8s82k5RZWe54zOsTQKT6Mj9bZNicRuKp/e95fvZeEiCAevbw3MWFBXD3zW649O5GdmXncPLwzw7slUFLqpqC4lEUb04kKCWRY1/jy8Ud5RS5CAp2nNJWQBppa0ECjlPKH7Pxilm3NpEebSFbvzKKo1M2QznHkFJTQs00Un27Yz5MLt5Bx2E790yoqGKcIqTnVB6jQQCehQU4OVRi3dM2gRM7plsDvPthA77bRvHbjWYQEnlz3bw00taCBRinVULlK3Ty16GcGd47jvO4tyS92sWxrJj3bRLJ2dza7MvN4apHtMTdpcEdaR4cwb30qm9MO43QIpW7DhT1bsXZ3VqWDZWdc158xvdsct74mNNDUggYapVRj9r/VewkLcjK2z9GAcbiwhPCgAHILS4gODSS/uJSwICczFm8nNNDBr87uyO5DeXRtGXnS59VAUwsaaJRSqvaqCjSNv+O2UkqpBk0DjVJKqTqlgUYppVSd0kCjlFKqTmmgUUopVac00CillKpTGmiUUkrVKQ00Siml6pQO2KyEiGQAu05y9wTgoA+z09jp/TiW3o9j6f04qinci47GmBYVV2qg8TERWVXZyNjmSu/HsfR+HEvvx1FN+V5o1ZlSSqk6pYFGKaVUndJA43sz/Z2BBkbvx7H0fhxL78dRTfZeaBuNUkqpOqUlGqWUUnVKA41SSqk6pYHGh0TkLhFZIyLfishsEYn1d57qiogkicgXIpJSybYLROQ7EVkiIktFpG+F7fEi8r7nPq0Rkan1lnEfE+tGEfnK87dORB4XkUCvNM3pflwuIgtEZJHnWhaISPcKafp57sMSz305v8L2EBF5SUS+9xzjMRGR+r0S3/J8TpZV/P/SbD4bxhj988EfMBHYAUR7lqcDH/s7X3V0rSOBRcB/gZQK2zoCuUB/z/IVwD4g3CvNp8AznvcxwG5ggr+v6yTvRYTnejt7Xc8vwF+a6f1YAFzmeS+ez8j3Xtsjgf3AeM/yWUAO0N4rzfPAB579g4Dvgbv9fW2neF+uA7K9/780p8+G3zPQVP6AFcCfvJa7Agbo4u+81cG1dsCWhv9cSaB5HPi6wro9wE2e990996Wj1/ZHgW/8fV0neS+CK34JAk8Dq5rp/RiAp5ORZ/kOINNr+VZge4V9lgJ/9byPAoqAc7223wzs9ve1ncI9ifAEy6cqBJpm89nQqjMf8FSTDATWl60zxmwF8oGh/spXXTHG7DHGuKvYPBSv++CxgaP3YSiQY4zxnuJnPTBIRJy+zWndM8YUGWP+WWF1KHDA87653Y/VxvONKCItgGuB57ySDMVev7f1HL0fA7ClmPUVtncQkQ51kum693vsPThSYX2z+WxooPGNFkAAkFVhfRbQuv6z41dtOPF9qGp7EBBXt1mreyISBFwCPONZ1Szvh4h8gq1KXoP9FV6mJvfDGGOyK2yHRvh/SUQ6A8OBNyrZ3Gw+GxpolPKtR4H/GWO+8HdG/MkYcyl2ksgwYKGINNfvmqeB35WV8pqr5vqP72sHARdQsZdZLJBW/9nxqzROfB+q2l7M8b/eGhURuR37K/R+r9XN9n4YYwqBh4DzgRGe1TW5HyIiMRW2QyP7vyQio4Ajxphvq0jSbD4bGmh8wBhTDKwGyrsmikgX7K+5Ff7Kl58sx+s+ePTh6H1YDkSLSKLX9r7YnkmueshfnRCRG4FzgWRjjFtE+ng2Nav7ISIPVliV53kN97xWdj/6cvR+rMJ+kfatsH2vMWaPD7NaHy4CuotIiqdbczLQz7N8B83ps+Hv3ghN5Q/4P2A7EOVZfpYm2r3Z65r/zPG9zpKw3VX7eZYvx3bZjPBK8xnwlOd9NLCTRthl0+t6rsN2643F9jCKwNMzqLndD2wHmNO9lv8AZABxnuUo7C/1Sz3LAzz3p4PXPi8A73O0e/N3NPLuzZ7rOub/S3P6bOhcZz4kIncB12N/ke0BphhjGlURtyZEpBPwGvY/SgywDtvXf65n+wXYrpuF2FLzr40xG7z2jwdmAO2x3YNnGWOm1+c1+IqItAb2Asf1AjLGiCdNc7ofdwP/D3utIdgv0geNMWu80vTD9sJye9I8YIz52mt7CHYc2pnY+zof+INppF9Wnh5iX3Ls/5ffGWO+ay6fDQ00Siml6pS20aj/3979vOgUxXEc/3xCKVkqJUwJC9IsNKWUaWLBQlMsxkYz5UdSSBTKP2AWLGajJiYLQ03ZKDX5MUoWbEizQDHExmIiaUj5WtxzZ56eHmnMnHsX3q+6fe8993nmnll9O+c+53wBICsSDQAgKxIN29gKzAAAAmVJREFUACArEg0AICsSDQAgKxINACArEg2Qie2uVLAq0vGyXCWejs+22yroR3sqyBa2Wc+AyrGOBsgoJZK36fJgRAw23BtTsWXNRAX96JT0QJpZSApUhRENUJ8BSZN1dwLIjUQDVMx2p+2hiBiRNGD7e5rWGrY9YvuT7Xu21zV8Z22698L203T0NP3dvjRF9sb2Hdujtne1eP4p2w9tf7F92TYjHGRFogGqczpNl10qGyJiv2a2hf8VEXslnZfUJem27UWpsuQTSXsk9UjqULHh5LDto5Jk+7CkKyo2rdwUETsl3VWxg3Cz5xGxTcVml4dUFGoDsiHRANXpj4hOSSf+cP9xiuU28WtVlPPtVbEZ49eIGE+bS5afOZnisRRHI6IsGTwo6XqL5zxK8WOKG2fxPwCztrDuDgD/m4gYkzTW4ta3pihJKyStatFenq9MsS3F6RLIETGpYiTU/Pyp8jTFxX/vNfDvGNEANbHd3fTz5iVNUSpGHe9btJfn5b2JFKcrU9peZnvzfPQVmAsSDVCfbs2MRKRimkyStqT4WsV02lUVI5Wltjekl/flZy6mWNYo2WG7TELn1PodDVApps6ATGxvl9Tf0HTW9oGG6zWShhquF9i+JWmrpPuSjkTET0kfbHeoKJB1U9KUimmvfRFxQ5Ii4rLtH5KOS3pm+52kcUkXbK9Xww8QbA+qKD3enpp6bb+KiFbvc4A5Y8EmUDPbE5JWS+qLiKF6ewPMP6bOAABZkWiAGtm+Jml5ujxje3ed/QFyYOoMAJAVIxoAQFYkGgBAViQaAEBWJBoAQFYkGgBAVr8Bz26HT7P0hMYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams.update({'font.size': 13})\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "import time\n",
    "\n",
    "plt.plot(history.history['loss'],label= 'loss')\n",
    "plt.plot(history.history['val_loss'],label='val_loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1321, 61)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = autoencoder.predict(X_test)\n",
    "\n",
    "\n",
    "print(pred.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### back to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PC_enc  F0_y_y   F1        F2   F3        F4        F5        F6  \\\n",
      "0  131023122942     0.0  0.0  0.157870  0.0  0.222532  0.276567  0.102942   \n",
      "1  131023156693     0.0  0.0  0.155769  0.0  0.216320  0.269327  0.079737   \n",
      "2  131023214462     0.0  0.0  0.177993  0.0  0.245764  0.296090  0.115659   \n",
      "3  131023214801     0.0  0.0  0.162611  0.0  0.226331  0.285585  0.088167   \n",
      "4  131023242322     0.0  0.0  0.159436  0.0  0.220113  0.259051  0.086809   \n",
      "\n",
      "         F7   F8  ...  F51_y  F52_y  F53_y     F54_y  F55_y  F56_y  F57_y  \\\n",
      "0  0.050764  0.0  ...    0.0    0.0    0.0  0.005536    0.0    0.0    0.0   \n",
      "1  0.073763  0.0  ...    0.0    0.0    0.0  0.010002    0.0    0.0    0.0   \n",
      "2  0.065848  0.0  ...    0.0    0.0    0.0  0.000000    0.0    0.0    0.0   \n",
      "3  0.075574  0.0  ...    0.0    0.0    0.0  0.010272    0.0    0.0    0.0   \n",
      "4  0.078694  0.0  ...    0.0    0.0    0.0  0.014799    0.0    0.0    0.0   \n",
      "\n",
      "   F58_y  F59_y  F60_y  \n",
      "0    0.0    0.0    0.0  \n",
      "1    0.0    0.0    0.0  \n",
      "2    0.0    0.0    0.0  \n",
      "3    0.0    0.0    0.0  \n",
      "4    0.0    0.0    0.0  \n",
      "\n",
      "[5 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(SP_pr_ts['PC_enc'].head())\n",
    "\n",
    "PC_enc_list = SP_pr_ts['PC_enc'].sort_values().tolist()\n",
    "df_new = pd.DataFrame(data=pred, columns=SP_pr_ts.columns[1:])\n",
    "PC_enc_list = SP_pr_ts['PC_enc'].sort_values().tolist()\n",
    "df_new['PC_enc'] = PC_enc_list\n",
    "df_new = df_new[['PC_enc']+ list(df_new.columns[0:-1])]\n",
    "print(df_new.head())\n",
    "\n",
    "#df_new = pd.concat([df_new, pd.DataFrame(data=pred, columns=SP_pr_ts.columns[1:])], axis=1)#.sort_values('PC_enc')\n",
    "\n",
    "#print(df_new.head())\n",
    "\n",
    "df_new.to_csv('evaluation/data/Model_ens_prov_id_pred.csv',index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 0 1 0 0]\n",
      "[0.00296615 0.         0.         0.         0.9133584  1.0397264\n",
      " 0.         0.9226485  0.         0.03729805]\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "print(X_test[i,:10])\n",
    "print(pred[i,:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  1,  8, 15, 29, 39]),)\n",
      "(array([ 0,  1,  8, 15, 29, 39]),)\n",
      "[1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0.98706645 1.0094048  0.         0.         0.         0.\n",
      " 0.         0.         1.0362589  0.         0.         0.\n",
      " 0.         0.         0.         0.99164975 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         1.1063786\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         1.0002358  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "eta = 0.2\n",
    "\n",
    "np1 = X_test#.to_numpy()[:,1:]\n",
    "np2 = pred#.to_numpy()[:,1:]\n",
    "\n",
    "i = 12\n",
    "\n",
    "print(np.where((np1[i,:]>eta).astype(int)))\n",
    "print(np.where((np2[i,:]>eta).astype(int)))\n",
    "\n",
    "print(np1[i,:])\n",
    "print(np2[i,:])\n",
    "\n",
    "#r = get_performance(df_test,df_model_ens_pred, 0.3)\n",
    "#print(r)\n",
    "\n",
    "#print(df_test.to_numpy()[i])\n",
    "#print(df_model_ens_pred.to_numpy()[i])\n",
    "#print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PC_enc    F0_y_y       F1        F2   F3        F4        F5  \\\n",
      "0  131091501475  0.000000  0.00000  0.981716  0.0  0.000000  0.000000   \n",
      "1  131214560515  0.000000  0.00000  0.000000  0.0  0.953292  0.000000   \n",
      "2  131091028338  0.000000  0.00000  0.961141  0.0  0.000000  0.028484   \n",
      "3  131090937788  0.002966  0.00000  0.000000  0.0  0.913358  1.039726   \n",
      "4  131213181257  0.989081  1.00959  0.000000  0.0  0.000000  0.000000   \n",
      "\n",
      "         F6        F7        F8  ...  F51_y  F52_y  F53_y  F54_y  F55_y  \\\n",
      "0  0.018934  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
      "1  0.938199  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
      "2  0.943942  0.000000  0.037403  ...    0.0    0.0    0.0    0.0    0.0   \n",
      "3  0.000000  0.922648  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
      "4  0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "   F56_y  F57_y  F58_y  F59_y  F60_y  \n",
      "0    0.0    0.0    0.0    0.0    0.0  \n",
      "1    0.0    0.0    0.0    0.0    0.0  \n",
      "2    0.0    0.0    0.0    0.0    0.0  \n",
      "3    0.0    0.0    0.0    0.0    0.0  \n",
      "4    0.0    0.0    0.0    0.0    0.0  \n",
      "\n",
      "[5 rows x 62 columns]\n",
      "           PC_enc  F0_y_y  F1  F2  F3  F4  F5  F6  F7  F8  ...  F51_y  F52_y  \\\n",
      "660  131023122942       0   0   1   0   0   0   0   0   0  ...      0      0   \n",
      "883  131023156693       0   0   0   0   1   0   1   0   0  ...      0      0   \n",
      "885  131023214462       0   0   1   0   0   0   1   0   0  ...      0      0   \n",
      "887  131023214801       0   0   0   0   1   1   0   1   0  ...      0      0   \n",
      "888  131023242322       1   1   0   0   0   0   0   0   0  ...      0      0   \n",
      "\n",
      "     F53_y  F54_y  F55_y  F56_y  F57_y  F58_y  F59_y  F60_y  \n",
      "660      0      0      0      0      0      0      0      0  \n",
      "883      0      0      0      0      0      0      0      0  \n",
      "885      0      0      0      0      0      0      0      0  \n",
      "887      0      0      0      0      0      0      0      0  \n",
      "888      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[5 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_new.head())\n",
    "print(SP_pr_ts.sort_values('PC_enc').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
